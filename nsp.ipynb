{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami\t\t\t\t     model_configs\t    setup.py\n",
      "checkpoints\t\t\t     model_utils.py\t    speachy\n",
      "checkpoints_done\t\t     nbests_ng.pkl\t    speachy.egg-info\n",
      "compute_rescore_wer.py\t\t     nbests.pkl\t\t    sweep.yaml\n",
      "distance_bias_LM_not_pretrained.svg  non_iid_dataloader.py  tedlium\n",
      "eval_perplexity.py\t\t     nsp.ipynb\t\t    tools.py\n",
      "experiment_configs\t\t     pos.pkl\t\t    train_LM.py\n",
      "ipynbs\t\t\t\t     ppls.pkl\t\t    train_lm.sh\n",
      "lm\t\t\t\t     __pycache__\t    wandb\n",
      "lm_utils.py\t\t\t     README.md\n",
      "log.txt\t\t\t\t     rescore_with_TLM.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-12 20:32:28 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-12 20:32:28 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import ami.non_iid_dataloader as non_iid_dataloader\n",
    "import ami.tools as tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tools.load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = non_iid_dataloader.get_eval_dataloader(\n",
    "    corpus['train'],\n",
    "    max_duration=1000000000000000000000,\n",
    "    return_speaker=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    b = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl = b['speakers']\n",
    "newspl = []\n",
    "for i, s in enumerate(spl):\n",
    "    if i == 0:\n",
    "        newspl.append(s)\n",
    "    if i > 0 and s != spl[i-1]:\n",
    "        newspl.append(s)\n",
    "len(newspl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.7388)\n",
      "tensor(17.1446)\n",
      "tensor(12.8210)\n",
      "tensor(11.3158)\n",
      "tensor(12.6218)\n",
      "tensor(9.5278)\n",
      "tensor(14.6145)\n",
      "tensor(6.6576)\n",
      "tensor(13.4072)\n",
      "tensor(11.5454)\n",
      "tensor(11.3442)\n",
      "tensor(17.1421)\n",
      "tensor(16.3477)\n",
      "tensor(13.0270)\n",
      "tensor(12.5084)\n",
      "tensor(18.8419)\n",
      "tensor(15.5277)\n",
      "tensor(10.4952)\n",
      "tensor(20.6362)\n",
      "tensor(15.4924)\n",
      "tensor(7.3422)\n",
      "tensor(5.9297)\n",
      "tensor(13.4303)\n",
      "tensor(11.0933)\n",
      "tensor(12.1473)\n",
      "tensor(6.9668)\n",
      "tensor(15.1166)\n",
      "tensor(9.7875)\n",
      "tensor(14.5545)\n",
      "tensor(12.6487)\n",
      "tensor(10.9061)\n",
      "tensor(12.6079)\n",
      "tensor(11.6783)\n",
      "tensor(16.7804)\n",
      "tensor(12.4397)\n",
      "tensor(18.7113)\n",
      "tensor(13.9517)\n",
      "tensor(15.2176)\n",
      "tensor(13.1902)\n",
      "tensor(10.3507)\n",
      "tensor(14.6679)\n",
      "tensor(12.9814)\n",
      "tensor(13.0851)\n",
      "tensor(10.2679)\n",
      "tensor(12.8914)\n",
      "tensor(20.2454)\n",
      "tensor(10.5298)\n",
      "tensor(14.3018)\n",
      "tensor(9.8730)\n",
      "tensor(16.5340)\n",
      "tensor(8.7985)\n",
      "tensor(13.7669)\n",
      "tensor(13.5679)\n",
      "tensor(15.8154)\n",
      "tensor(11.4349)\n",
      "tensor(9.0904)\n",
      "tensor(10.4825)\n",
      "tensor(16.4804)\n",
      "tensor(17.7092)\n",
      "tensor(15.6773)\n",
      "tensor(13.5371)\n",
      "tensor(13.8929)\n",
      "tensor(15.8224)\n",
      "tensor(12.0622)\n",
      "tensor(12.7186)\n",
      "tensor(14.6605)\n",
      "tensor(16.8343)\n",
      "tensor(13.7462)\n",
      "tensor(13.3201)\n",
      "tensor(12.3202)\n",
      "tensor(10.9287)\n",
      "tensor(13.6018)\n",
      "tensor(12.5618)\n",
      "tensor(14.0718)\n",
      "tensor(12.2291)\n",
      "tensor(11.3484)\n",
      "tensor(11.4207)\n",
      "tensor(9.5547)\n",
      "tensor(10.2292)\n",
      "tensor(13.7055)\n",
      "tensor(11.9941)\n",
      "tensor(11.4622)\n",
      "tensor(15.8797)\n",
      "tensor(13.7727)\n",
      "tensor(8.3534)\n",
      "tensor(10.5153)\n",
      "tensor(15.7484)\n",
      "tensor(15.2555)\n",
      "tensor(16.0992)\n",
      "tensor(11.7996)\n",
      "tensor(11.7000)\n",
      "tensor(12.7317)\n",
      "tensor(7.5602)\n",
      "tensor(12.2966)\n",
      "tensor(8.1573)\n",
      "tensor(18.5474)\n",
      "tensor(12.4767)\n",
      "tensor(17.3671)\n",
      "tensor(10.0685)\n",
      "tensor(10.1408)\n",
      "tensor(12.4642)\n",
      "tensor(14.1683)\n",
      "tensor(13.1731)\n",
      "tensor(12.5948)\n",
      "tensor(15.2029)\n",
      "tensor(15.4975)\n",
      "tensor(17.7924)\n",
      "tensor(10.5871)\n",
      "tensor(12.8455)\n",
      "tensor(12.3286)\n",
      "tensor(18.3637)\n",
      "tensor(10.1172)\n",
      "tensor(10.3057)\n",
      "tensor(16.6167)\n",
      "tensor(16.5704)\n",
      "tensor(14.6016)\n",
      "tensor(11.2037)\n",
      "tensor(10.4801)\n",
      "tensor(13.4406)\n",
      "tensor(12.2191)\n",
      "tensor(12.7572)\n",
      "tensor(18.5052)\n",
      "tensor(12.4497)\n",
      "tensor(10.2112)\n",
      "tensor(11.5800)\n",
      "tensor(7.3024)\n",
      "tensor(12.8366)\n",
      "tensor(7.5484)\n",
      "tensor(17.4030)\n",
      "tensor(15.8887)\n",
      "tensor(14.8280)\n",
      "tensor(16.0226)\n"
     ]
    }
   ],
   "source": [
    "spms  = []\n",
    "for batch in dl:\n",
    "    b = batch\n",
    "    spl = b['speakers']\n",
    "    newspl = []\n",
    "    for i, s in enumerate(spl):\n",
    "        if i == 0:\n",
    "            newspl.append(s)\n",
    "        if i > 0 and s != spl[i-1]:\n",
    "            newspl.append(s)\n",
    "    spm = len(newspl) / ((b['audio_lens'].sum()/16000)/60)\n",
    "    print(spm)\n",
    "    spms.append(spm)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5801)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(torch.as_tensor(spms).mean() /60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
