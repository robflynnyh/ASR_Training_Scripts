{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cache_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m8\u001b[39m])\n\u001b[1;32m      2\u001b[0m cur_lens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m7\u001b[39m])\n\u001b[1;32m      3\u001b[0m total_len \u001b[38;5;241m=\u001b[39m cache_lens \u001b[38;5;241m+\u001b[39m cur_lens\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "cache_len = torch.tensor([2,5,2,8])\n",
    "cur_lens = torch.tensor([5,2,5,7])\n",
    "total_len = cache_lens + cur_lens\n",
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'causal_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m causal_mask\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'causal_mask' is not defined"
     ]
    }
   ],
   "source": [
    "causal_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39marange(causal_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.arange(causal_mask.shape[0])[None].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cache_lens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (cache_lens[:,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(cur_lens\u001b[38;5;241m.\u001b[39mmax())[\u001b[38;5;28;01mNone\u001b[39;00m,:,\u001b[38;5;28;01mNone\u001b[39;00m])\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cache_lens' is not defined"
     ]
    }
   ],
   "source": [
    "(cache_lens[:,None,None] + torch.arange(cur_lens.max())[None,:,None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 15])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(total_len.max())[None,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_len, cur_lens, cache_len)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_len' is not defined"
     ]
    }
   ],
   "source": [
    "print(total_len, cur_lens, cache_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repeat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m repeat(torch\u001b[38;5;241m.\u001b[39marange(total_len\u001b[38;5;241m.\u001b[39mmax()), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi -> b r i\u001b[39m\u001b[38;5;124m'\u001b[39m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(total_len), r\u001b[38;5;241m=\u001b[39mcur_lens\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m      2\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m causal_mask \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (cache_lens[:,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(cur_lens\u001b[38;5;241m.\u001b[39mmax())[\u001b[38;5;28;01mNone\u001b[39;00m,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m causal_mask[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'repeat' is not defined"
     ]
    }
   ],
   "source": [
    "causal_mask = repeat(torch.arange(total_len.max()), 'i -> b r i', b=len(total_len), r=cur_lens.max())\n",
    "causal_mask = causal_mask >= (cache_lens[:,None,None] + torch.arange(cur_lens.max())[None,:,None] + 1)\n",
    "causal_mask[-3,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_mask = torch.arange(total_len.max()).expand(len(total_len), -1)\n",
    "causal_mask = causal_mask > cache_len[:,None]\n",
    "causal_mask = causal_mask < torch.arange(causal_mask.shape[0])[None].T + cache_len[:,None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 6],\n",
       "        [ 4],\n",
       "        [11]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(causal_mask.shape[0])[None].T + cache_len[:,None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "x_len = torch.tensor([7,6,4])\n",
    "cache_len = torch.tensor([6,7,9])\n",
    "total_len = x_len + cache_len\n",
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_mask = repeat(torch.arange(total_len.max()), 'i -> b r i', b=len(total_len), r=x_len.max())\n",
    "cache_offset = cache_len[:,None,None] \n",
    "diagonal_offset = torch.arange(x_len.max())[None,:,None]\n",
    "positional_grid = causal_mask - cache_offset - diagonal_offset # used for positional bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 13])"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  8,  7,  6,  5,  4,  3,  2,  1,  0, -1, -2, -3],\n",
       "        [10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0, -1, -2],\n",
       "        [11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0, -1],\n",
       "        [12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0],\n",
       "        [13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1],\n",
       "        [14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2],\n",
       "        [15, 14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3]])"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_grid[2]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_len[:,None,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6]]])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_len-cache_len-1).max()[None,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,   5,   6],\n",
       "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,   5],\n",
       "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4],\n",
       "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3],\n",
       "        [-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2],\n",
       "        [-11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1],\n",
       "        [-12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0]])"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 13, 1])"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[((positional_grid*-1) + (total_len-cache_len-1).max())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, indices_p = pos(i=7, j=13, device='cpu', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 7, 13])\n"
     ]
    }
   ],
   "source": [
    "i,j = 7,13\n",
    "indices = ((positional_grid*-1) + (total_len-cache_len-1).max())\n",
    "pos = torch.arange(positional_grid.min(), positional_grid.max()+1).flip(0)[:,None]\n",
    "dpos = DynamicPositionBias(dim=64, depth=2, heads=1, activation=nn.SiLU)(pos=pos, indices=indices, dtype=torch.float32, device='cpu').detach()\n",
    "print(dpos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos.pkl', 'rb') as f:\n",
    "    pos = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdae217c280>]"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dpos = DynamicPositionBias(dim=64, depth=2, heads=1, activation=nn.SiLU)\n",
    "poos = dpos(pos=pos['pos'], indices=pos['positional_indices'], dtype=torch.float32, device='cpu').detach()\n",
    "poos.shape\n",
    "plt.plot(poos[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pos', 'positional_indices'])"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdae2824d30>]"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dpos[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleit(obj, path):\n",
    "    import pickle as pkl\n",
    "    with open(path, 'wb') as f:\n",
    "        pkl.dump(obj, f)\n",
    "\n",
    "def loadit(path):\n",
    "    import pickle as pkl\n",
    "    with open(path, 'rb') as f:\n",
    "        return pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch import einsum\n",
    "from torch.utils.checkpoint import checkpoint # # gradient/activation checkpointing\n",
    "from functools import partial\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "GLOBAL_NUM = 0\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "# token shifting\n",
    "# lucidrains implementation: https://github.com/lucidrains/x-transformers/blob/main/x_transformers/x_transformers.py\n",
    "# BlinkDL idea from RWKV-LM https://github.com/BlinkDL/RWKV-LM\n",
    "def shift(t, amount, mask = None):\n",
    "    if amount == 0:\n",
    "        return t\n",
    "    else:\n",
    "        amount = min(amount, t.shape[1])\n",
    "\n",
    "    if exists(mask):\n",
    "        t = t.masked_fill(~mask[..., None], 0.)\n",
    "\n",
    "    return F.pad(t, (0, 0, amount, -amount), value = 0.)\n",
    "\n",
    "class ShiftTokens(nn.Module):\n",
    "    def __init__(self, shifts, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.shifts = tuple(shifts)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        mask = kwargs.get('mask', None)\n",
    "        shifts = self.shifts\n",
    "        segments = len(shifts)\n",
    "        feats_per_shift = x.shape[-1] // segments\n",
    "        splitted = x.split(feats_per_shift, dim = -1)\n",
    "        segments_to_shift, rest = splitted[:segments], splitted[segments:]\n",
    "        segments_to_shift = list(map(lambda args: shift(*args, mask = mask), zip(segments_to_shift, shifts)))\n",
    "        x = torch.cat((*segments_to_shift, *rest), dim = -1)\n",
    "        return self.fn(x, **kwargs)\n",
    "\n",
    "\n",
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False, activation=nn.SiLU):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            activation()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                activation()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "\n",
    "    def forward(self, pos, indices, device, dtype):\n",
    "        pos = pos.to(device=device, dtype=dtype)\n",
    "        \n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos) \n",
    "      \n",
    "        bias = pos[indices]\n",
    "        #print(bias.shape)\n",
    "        bias = rearrange(bias, 'b i j h -> b h i j')\n",
    "        return bias\n",
    "\n",
    "class ScaledSinuEmbedding(nn.Module):\n",
    "    '''taken From Phil Wang's x-transformers library'''\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(1,))\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, device = x.shape[1], x.device\n",
    "        t = torch.arange(n, device = device).type_as(self.inv_freq)\n",
    "        sinu = einsum('i , j -> i j', t, self.inv_freq)\n",
    "        emb = torch.cat((sinu.sin(), sinu.cos()), dim = -1)\n",
    "        return emb * self.scale\n",
    "\n",
    "class ReLUSquared(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.pow(F.relu(x), 2)\n",
    "\n",
    "def l2norm(t, groups = 1, dim = -1):\n",
    "    if groups == 1:\n",
    "        return F.normalize(t, p = 2, dim = dim)\n",
    "    t = rearrange(t, '... (g d) -> ... g d', g = groups)\n",
    "    t = F.normalize(t, p = 2, dim = dim)\n",
    "    return rearrange(t, '... g d -> ... (g d)')\n",
    "\n",
    "class CosineAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats,\n",
    "        head_dim,\n",
    "        n_heads,\n",
    "        dropout=0.1,\n",
    "        bias=False,\n",
    "        temperature=15.5,\n",
    "        return_attention=False,\n",
    "        causal=False,\n",
    "        activation='softmax',\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert activation in ['relusq', 'softmax']\n",
    "        self.shared_kv = kwargs.get('shared_kv', False)\n",
    "        self.talking_heads = kwargs.get('talking_heads', False)\n",
    "\n",
    "        self.n_feats, self.head_dim, self.n_heads = n_feats, head_dim, n_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bias = bias\n",
    "        self.return_attention = return_attention\n",
    "        self.causal = causal\n",
    "\n",
    "        if self.talking_heads:\n",
    "            self._head_proj = nn.Conv2d(n_heads, n_heads, (1, 1))\n",
    "\n",
    "        self.temperature = torch.nn.Parameter(torch.tensor(temperature), requires_grad=True) if isinstance(temperature, float) else temperature\n",
    "\n",
    "        self.activation = ReLUSquared() if activation == 'relusq' else nn.Softmax(dim=-1)\n",
    "\n",
    "        if not self.shared_kv:\n",
    "            self.qkv_proj = nn.Linear(n_feats, 3 * n_heads * head_dim, bias=bias)\n",
    "            self.qkv = lambda x: rearrange(self.qkv_proj(x), \"b n (h d qkv) -> qkv b h n d\", qkv=3, h=n_heads, d=head_dim)\n",
    "        else:\n",
    "            self.q_proj, self.kv_proj = [nn.Linear(n_feats, el, bias=bias) for el in [n_heads * head_dim, 2 * head_dim]]\n",
    "            map_q, map_kv = lambda q: rearrange(q, 'b n (h d) -> b h n d', h=n_heads), lambda kv: rearrange(kv, 'b n (kv d) -> kv b () n d', kv=2, d=head_dim)\n",
    "            self.qkv = lambda x: (map_q(self.q_proj(x)), *map_kv(self.kv_proj(x)))\n",
    "\n",
    "        self.out_proj = nn.Linear(n_heads * head_dim, n_feats, bias=bias)\n",
    "    \n",
    "    def head_proj(self, dots):\n",
    "        if not self.talking_heads:\n",
    "            return dots\n",
    "        dots = self._head_proj(dots)\n",
    "        return dots      \n",
    "\n",
    "    def attend(self, query, key, value, attn_mask, pos_bias):\n",
    "        query, key = map(l2norm, (query, key))\n",
    "        \n",
    "        dots = einsum('bhid,bhjd->bhij', query, key) * self.temperature\n",
    "        dots = self.head_proj(dots)\n",
    "        #print(dots.shape, pos_bias.shape)\n",
    "        #dots += pos_bias  \n",
    "\n",
    "        dots.masked_fill_(attn_mask, -torch.finfo(dots.dtype).max)\n",
    "\n",
    "        attn = self.activation(dots)\n",
    "     \n",
    "        attn = self.dropout(attn)\n",
    "        return einsum(\"bhij,bhjd->bhid\", attn, value)\n",
    "\n",
    "\n",
    "    def attach_cache(self, kv, cache, cache_indices):\n",
    "        kv = torch.stack(kv, dim=0)\n",
    "        if cache is None:\n",
    "            return kv\n",
    "        zero_vector = torch.zeros_like(kv[:, :, :, :1, :])\n",
    "        kv_w_cache = torch.cat([cache, kv, zero_vector], dim=-2)\n",
    "        #print(kv_w_cache.shape)\n",
    "        kv_w_cache = torch.gather(kv_w_cache, dim=-2, index=cache_indices) # we do this to remove unnecessary padding\n",
    "        return kv_w_cache\n",
    "\n",
    "    def forward(self, x, pos_bias, mask, cache=None, cache_indices=None):\n",
    "        B, N, C, H, D = *x.shape, self.n_heads, self.head_dim\n",
    "    \n",
    "        q, k, v  = self.qkv(x)\n",
    "        kv = self.attach_cache([k, v], cache, cache_indices)\n",
    "        k, v = kv\n",
    "\n",
    "        out = self.attend(q, k, v, mask, pos_bias)\n",
    "\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "        out = self.out_proj(out)\n",
    "        return out, kv\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(self.norm(x), *args, **kwargs)\n",
    "\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, activation):\n",
    "        super().__init__()\n",
    "        self.act = activation\n",
    "        self.proj = nn.Linear(dim_in, dim_out * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, gate = self.proj(x).chunk(2, dim = -1)\n",
    "        return x * self.act(gate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class transformer(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            dim, \n",
    "            depth, \n",
    "            heads, \n",
    "            dim_head, \n",
    "            causal=True,\n",
    "            temperature=15.5,\n",
    "            shared_temperture=False,\n",
    "            intermediate_loss=True,\n",
    "            dropout = 0.1,\n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__()\n",
    "        if depth == 1:\n",
    "            intermediate_loss = False\n",
    "\n",
    "        ff_mult = kwargs.get('ff_mult', 4)\n",
    "        self.checkpoint_every_n = kwargs.get('checkpoint_every_n', 0)\n",
    "        self.token_shift = kwargs.get('token_shift', False)\n",
    "        self.causal = causal\n",
    "\n",
    "        self.temperature = nn.Parameter(torch.tensor(temperature), requires_grad=True) if shared_temperture else temperature\n",
    "    \n",
    "\n",
    "        self.intermediate_loss = intermediate_loss\n",
    "\n",
    "        self.depth = depth\n",
    "        self.positional_bias = DynamicPositionBias(\n",
    "            dim = dim // 4,\n",
    "            heads = heads,\n",
    "            depth = 2,\n",
    "            log_distance = False,\n",
    "            norm = False\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.token_shifter = lambda x: x\n",
    "        if self.token_shift:\n",
    "            self.token_shifter = ShiftTokens(range(0, 2), nn.Identity())\n",
    "        self.token_shift = lambda x: self.token_shifter(x)\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, CosineAttention(\n",
    "                    dim, \n",
    "                    n_heads=heads, \n",
    "                    head_dim=dim_head, \n",
    "                    causal=causal,\n",
    "                    temperature=self.temperature,\n",
    "                    dropout=dropout,\n",
    "                    **kwargs\n",
    "                )),\n",
    "                PreNorm(dim, self.ff(dim, mult=ff_mult))\n",
    "            ]))\n",
    "\n",
    "    @staticmethod\n",
    "    def ff(dim, mult=4, dropout=0.1):\n",
    "        return nn.Sequential(\n",
    "            GLU(dim, dim * mult, nn.SiLU()),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * mult, dim)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_custom_forward(module):\n",
    "        def custom_forward(*args, **kwargs):\n",
    "            return module(*args, **kwargs)\n",
    "        return custom_forward\n",
    "\n",
    "    def checkpoint(self, layer, module, *args, **kwargs):\n",
    "        condition = self.training and self.checkpoint_every_n != 0 and layer < self.depth - 1 and layer % self.checkpoint_every_n == 0\n",
    "        return checkpoint(self.create_custom_forward(module), *args, **kwargs) if condition else module(*args, **kwargs)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cache(cache, layer):\n",
    "        if cache is None:\n",
    "            return None\n",
    "        return cache['cache'][layer]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cache_indices(x_lens, cache_lens, cache_kv, x):  \n",
    "        # used later w/ gather to remove padding when cache is concatenated with current input to remove padding\n",
    "        max_new_len = (x_lens + cache_lens).max()\n",
    "\n",
    "        B, H, N, D = x.shape[0], 1, (x.shape[1] + cache_kv.shape[-2]), cache_kv.shape[-1]\n",
    "        indices = []\n",
    "        for i in range(B): # stinky for loop to sort out indices for gather \n",
    "            cache_indices = torch.arange(cache_lens[i], device='cpu')\n",
    "            total_length = cache_lens[i] + x_lens[i]\n",
    "            diff_from_max_len = max_new_len - total_length\n",
    "            x_indices = torch.arange(x_lens[i]+diff_from_max_len, device='cpu') + cache_kv.shape[-2]\n",
    "            if diff_from_max_len > 0:\n",
    "                x_indices[-diff_from_max_len:] = N # last index will be used for padding\n",
    "            new_indices = torch.cat([cache_indices, x_indices])\n",
    "            indices.append(new_indices)\n",
    "\n",
    "        indices = torch.stack(indices, dim=0)\n",
    "        \n",
    "        indices = rearrange(indices, 'b n -> () b () n ()').expand(2, B, H,-1, D) # 2 for key and value\n",
    "        return indices.to(x.device)\n",
    "\n",
    "\n",
    "    def create_masks_and_positions(self, x, length, cache): # could clean this up ):\n",
    "        x_len = length if length is not None else torch.tensor(x.shape[-2]).expand(x.shape[0])\n",
    "        cache_len = cache['cache_lengths'] if exists(cache) else 0\n",
    "        total_len = x_len + cache_len\n",
    "        kv_mask = torch.arange(total_len.max(), device=x.device).expand(len(total_len), -1) >= total_len.unsqueeze(-1)\n",
    "        q_mask = torch.arange(x_len.max(), device=x.device).expand(len(x_len), -1) >= x_len.unsqueeze(-1)\n",
    "        attn_mask = ~(rearrange(~q_mask, \"b n -> b () n ()\") * rearrange(~kv_mask, \"b n -> b () () n\"))\n",
    "\n",
    "        causal_mask = repeat(torch.arange(total_len.max()), 'i -> b r i', b=len(total_len), r=x_len.max())\n",
    "        cache_offset = cache_len[:,None,None] if exists(cache) else cache_len\n",
    "        diagonal_offset = torch.arange(x_len.max())[None,:,None]\n",
    "\n",
    "        ## positional stuff ##\n",
    "        global GLOBAL_NUM \n",
    "        GLOBAL_NUM += 1\n",
    "        positional_grid = causal_mask - cache_offset - diagonal_offset \n",
    "        pos = torch.arange(positional_grid.min(), positional_grid.max()+1).flip(0)[:,None]\n",
    "        positional_indices = ((positional_grid*-1) + (total_len-cache_len-1).max()) # shifted so smallest value is 0 (for indexing)\n",
    "        #print(pos.shape, positional_indices.shape)\n",
    "        pos_bias = self.positional_bias(pos=pos, indices=positional_indices, dtype=x.dtype, device=x.device)\n",
    "        print(GLOBAL_NUM)\n",
    "        if GLOBAL_NUM == 3:\n",
    "            pickleit(pos[positional_indices], 'pos.pkl')\n",
    "            raise MemoryError()\n",
    "            print(pos[positional_indices].shape)\n",
    "        ## positional stuff ##\n",
    "        \n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = causal_mask >= (cache_offset + diagonal_offset + 1)\n",
    "            attn_mask = torch.logical_or(attn_mask, causal_mask[:,None])\n",
    "            \n",
    "        return q_mask, attn_mask, total_len, x_len, cache_len, pos_bias\n",
    "\n",
    "    def forward(self, x, length=None, self_condtioning=None, cache=None):\n",
    "        intermediate_logits = []\n",
    "        cached_kvs = []\n",
    "    \n",
    "        mask, attn_mask, total_lens, x_len, cache_len, pos_bias = self.create_masks_and_positions(x, length, cache)\n",
    "    \n",
    "        #print(cache_len if exists(cache) else None)\n",
    "        cache_indices = self.get_cache_indices(x_len, cache_len, cache['cache'], x) if exists(cache) else None\n",
    "\n",
    "    \n",
    "        for i, (attn, ff) in enumerate(self.layers):\n",
    "\n",
    "            x = self.token_shift(x)\n",
    "            a_out, kv = self.checkpoint(i, attn, x, pos_bias, attn_mask, self.get_cache(cache, layer=i), cache_indices)\n",
    "            x = a_out + x\n",
    "            cached_kvs.append(kv)\n",
    "            x = self.checkpoint(i, ff, x) + x   \n",
    "\n",
    "            if i < self.depth - 1 and self_condtioning is not None:\n",
    "                x, logits = self_condtioning(x)\n",
    "                intermediate_logits.append(logits)\n",
    "\n",
    "        if len(intermediate_logits) > 0: # stack intermediate logits\n",
    "            intermediate_logits = torch.stack(intermediate_logits, dim=0) # D x B x N x L\n",
    "\n",
    "        cached_kvs = torch.stack(cached_kvs, dim=0) if len(cached_kvs) > 0 else None\n",
    "        cached_kvs = {'cache_lengths': total_lens, 'cache': cached_kvs} if exists(cached_kvs) else None\n",
    "\n",
    "\n",
    "        return x, intermediate_logits, cached_kvs\n",
    "\n",
    "class shared_embedding_output_layer(nn.Module):\n",
    "    '''Pass a embedding layer and then use this module as the output layer'''\n",
    "    def __init__(self, embedding_layer, bias=False):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.use_bias = bias\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(embedding_layer.weight.shape[0]))#\n",
    "            nn.init.xavier_uniform_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.linear(x, weight=self.embedding_layer.weight, bias=self.bias if self.use_bias else None)\n",
    "\n",
    "\n",
    "class transformer_lm(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        vocab_size,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        causal=True,\n",
    "        temperature=15.5,\n",
    "        dropout=0.,\n",
    "        shared_temperture=True,\n",
    "        self_conditioning=False,\n",
    "        intermediate_loss=True,\n",
    "        use_abs_pos=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if depth == 1:\n",
    "            self_conditioning == False\n",
    "\n",
    "        self.self_conditioning = True if self_conditioning else None\n",
    "        self.intermediate_loss = intermediate_loss\n",
    "\n",
    "        self.use_abs_pos = use_abs_pos\n",
    "        if self.use_abs_pos:\n",
    "            self.abs_pos_fn = ScaledSinuEmbedding(dim=dim)\n",
    "        self.abs_pos = lambda x: x + self.abs_pos_fn(x) if self.use_abs_pos else x\n",
    "\n",
    "        if self_conditioning:\n",
    "            self.reprojection_layer = nn.Linear(vocab_size, dim)\n",
    "\n",
    "\n",
    "        self.layers = transformer(\n",
    "            dim = dim, \n",
    "            depth = depth, \n",
    "            heads = heads, \n",
    "            dim_head = dim_head, \n",
    "            causal = causal, \n",
    "            dropout = dropout,\n",
    "            temperature = temperature,\n",
    "            shared_temperture = shared_temperture,\n",
    "            intermediate_loss = intermediate_loss,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.tie_embedding = kwargs.get('tie_embedding', False)\n",
    "        print('Tie embedding:', self.tie_embedding) if self.tie_embedding else None\n",
    " \n",
    "        self.embedding = nn.Embedding(vocab_size, dim)\n",
    "\n",
    "        self.to_logits = shared_embedding_output_layer(self.embedding) if self.tie_embedding else nn.Linear(dim, vocab_size)\n",
    "        \n",
    "\n",
    "        self.post_norm = nn.LayerNorm(dim)\n",
    "\n",
    "\n",
    "    def self_condition_fn(self):\n",
    "        def self_condition(x):\n",
    "            logits = self.to_logits(self.post_norm(x))\n",
    "            if self.self_conditioning: # not effective for LMs (intermediate loss is tho)\n",
    "                z = F.softmax(logits, dim=-1)\n",
    "                z = self.reprojection_layer(z)\n",
    "                x = z + x\n",
    "            return x, logits\n",
    "        return self_condition if (self.self_conditioning or self.intermediate_loss) and self.training else None\n",
    "\n",
    "\n",
    "    def forward(self, x, length=None, cache:Dict=None):\n",
    "        '''\n",
    "        x: [B, N] (embedding indices)\n",
    "        length: [B] (length of each sequence)\n",
    "        cache: {cache_lengths: [B, N], cache: [L, KV, B, H, N, D]} KV: key and value (2)\n",
    "        '''\n",
    "        x = self.embedding(x)\n",
    "        x = self.abs_pos(x) \n",
    "  \n",
    "        x, interim_logits, cached_kvs = self.layers(x, length, self_condtioning=self.self_condition_fn(), cache=cache)\n",
    "        x = self.post_norm(x)\n",
    "        x = self.to_logits(x)\n",
    "\n",
    "        return  x, interim_logits, cached_kvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def collate_fn(tensors:List[torch.Tensor], pad_token:int):\n",
    "    max_len = max([t.shape[0] for t in tensors])\n",
    "    lengths = torch.tensor([t.shape[0] for t in tensors])\n",
    "    padded_tensors = [torch.cat([t, torch.full((max_len - t.shape[0],), pad_token, dtype=t.dtype)], dim=0) for t in tensors]\n",
    "    return torch.stack(padded_tensors, dim=0), lengths\n",
    "class CharacterTokenizer(): # only for testing\n",
    "    def __init__(self):\n",
    "        self.vocab = ['#', '/'] + list(string.ascii_lowercase) + [' '] # bos/eos -> /, pad -> #\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.token_to_id = {token: i for i, token in enumerate(self.vocab)}\n",
    "        self.id_to_token = {i: token for i, token in enumerate(self.vocab)}\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        return self.tokenize(text)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [self.token_to_id[token] for token in text]\n",
    "\n",
    "tokenizer = CharacterTokenizer()\n",
    "model = transformer_lm(\n",
    "    dim = 256,\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    depth = 10,\n",
    "    heads = 1,\n",
    "    dim_head = 32,\n",
    "    dropout=0.0,\n",
    "    causal = True,\n",
    "    shared_kv = True,\n",
    ")\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 12,  9]) tensor([6, 7, 6]) tensor([6, 5, 3])\n",
      "tensor([17, 18, 14])\n"
     ]
    }
   ],
   "source": [
    "print(b1_lengths + b2_lengths, b1_lengths, b2_lengths)\n",
    "print(fb_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THE LENGTHS TO MAKE THE CAUSAL MASK RATHER THAN THE OTHER THINGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12,  9])"
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_kvs_s2['cache_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1195], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m logits_s1, interim_logits, cached_kvs \u001b[38;5;241m=\u001b[39m model(b1, length\u001b[38;5;241m=\u001b[39mb1_lengths)\n\u001b[1;32m     14\u001b[0m logits_s2, interim_logits, cached_kvs_s2 \u001b[38;5;241m=\u001b[39m model(b2, length\u001b[38;5;241m=\u001b[39mb2_lengths, cache\u001b[38;5;241m=\u001b[39mcached_kvs)\n\u001b[0;32m---> 15\u001b[0m logits_s3, interim_logits, cached_kvs_s3 \u001b[38;5;241m=\u001b[39m model(b3, length\u001b[38;5;241m=\u001b[39mb3_lengths, cache\u001b[38;5;241m=\u001b[39mcached_kvs_s2)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#print('third')\u001b[39;00m\n\u001b[1;32m     17\u001b[0m logits_fs, interim_logits, cached_kvs_fs \u001b[38;5;241m=\u001b[39m model(fb, length\u001b[38;5;241m=\u001b[39mfb_lengths)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [1190], line 482\u001b[0m, in \u001b[0;36mtransformer_lm.forward\u001b[0;34m(self, x, length, cache)\u001b[0m\n\u001b[1;32m    479\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m    480\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabs_pos(x) \n\u001b[0;32m--> 482\u001b[0m x, interim_logits, cached_kvs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_condtioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_condition_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_norm(x)\n\u001b[1;32m    484\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_logits(x)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [1190], line 364\u001b[0m, in \u001b[0;36mtransformer.forward\u001b[0;34m(self, x, length, self_condtioning, cache)\u001b[0m\n\u001b[1;32m    361\u001b[0m intermediate_logits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    362\u001b[0m cached_kvs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 364\u001b[0m mask, attn_mask, total_lens, x_len, cache_len, pos_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_masks_and_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m#print(cache_len if exists(cache) else None)\u001b[39;00m\n\u001b[1;32m    367\u001b[0m cache_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_cache_indices(x_len, cache_len, cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m'\u001b[39m], x) \u001b[38;5;28;01mif\u001b[39;00m exists(cache) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [1190], line 349\u001b[0m, in \u001b[0;36mtransformer.create_masks_and_positions\u001b[0;34m(self, x, length, cache)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GLOBAL_NUM \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    348\u001b[0m     pickleit(pos[positional_indices], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m()\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pos[positional_indices]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m## positional stuff ##\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s1_b1, s2_b1, s3_b1 = torch.tensor(tokenizer('/hello')), torch.tensor(tokenizer('/buenos')), torch.tensor(tokenizer('/whats'))\n",
    "s1_b2, s2_b2, s3_b2 = torch.tensor(tokenizer(' world')), torch.tensor(tokenizer(' dias')), torch.tensor(tokenizer(' up'))\n",
    "s1_b3, s2_b3, s3_b3 = torch.tensor(tokenizer(' woo/')), torch.tensor(tokenizer(' mate/')), torch.tensor(tokenizer(' bro/'))\n",
    "b1, b1_lengths = collate_fn([s1_b1, s2_b1, s3_b1], pad_token=tokenizer.token_to_id['#'])\n",
    "b2, b2_lengths = collate_fn([s1_b2, s2_b2, s3_b2], pad_token=tokenizer.token_to_id['#'])\n",
    "b3, b3_lengths = collate_fn([s1_b3, s2_b3, s3_b3], pad_token=tokenizer.token_to_id['#'])\n",
    "# comparsion set\n",
    "f_1, f_2, f_3 = torch.tensor(tokenizer('/hello world woo/')), torch.tensor(tokenizer('/buenos dias mate/')), torch.tensor(tokenizer('/whats up bro/'))\n",
    "fb, fb_lengths = collate_fn([f_1, f_2, f_3], pad_token=tokenizer.token_to_id['#'])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_s1, interim_logits, cached_kvs = model(b1, length=b1_lengths)\n",
    "    logits_s2, interim_logits, cached_kvs_s2 = model(b2, length=b2_lengths, cache=cached_kvs)\n",
    "    logits_s3, interim_logits, cached_kvs_s3 = model(b3, length=b3_lengths, cache=cached_kvs_s2)\n",
    "    #print('third')\n",
    "    logits_fs, interim_logits, cached_kvs_fs = model(fb, length=fb_lengths)\n",
    "\n",
    "#logits_s1.masked_fill_(b1_lengths_mask.unsqueeze(-1), 0)\n",
    "\n",
    "#print('logits_s2:', logits_s2.shape, 'logits_fs:', logits_fs.shape)\n",
    "D, B = 1, 1\n",
    "#print(logits_s2[B, :, D], logits_fs[B, :, D])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = loadit('pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 7, 6]) tensor([6, 5, 3]) tensor([5, 6, 5]) tensor([17, 18, 14])\n"
     ]
    }
   ],
   "source": [
    "print(b1_lengths, b2_lengths, b3_lengths, fb_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12,  9])"
      ]
     },
     "execution_count": 1204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_kvs_s2['cache_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 18])"
      ]
     },
     "execution_count": 1202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.squeeze()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,   4,\n",
       "           5,   6,   7,   8],\n",
       "        [-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,\n",
       "           4,   5,   6,   7],\n",
       "        [-11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n",
       "           3,   4,   5,   6],\n",
       "        [-12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,\n",
       "           2,   3,   4,   5],\n",
       "        [-13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,\n",
       "           1,   2,   3,   4],\n",
       "        [-14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,\n",
       "           0,   1,   2,   3]])"
      ]
     },
     "execution_count": 1208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2, 3, 1, 18, 32]), torch.Size([10, 2, 3, 1, 18, 32]))"
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_cache.shape, cached_kvs_s3['cache'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 7, 6]), tensor([6, 5, 3]), tensor([5, 6, 5]))"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_lengths, b2_lengths, b3_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 18, 14])"
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_kvs_fs['cache_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:  torch.Size([10, 2, 3, 1, 18, 32]) torch.Size([10, 2, 3, 1, 12, 32])\n",
      "tensor([ 1.0158,  0.5204,  0.7300,  1.2198,  0.3039,  0.1603, -0.4030,  0.7707,\n",
      "         0.9710, -0.8434,  0.2548, -0.6090,  0.0468,  1.5075, -0.1081,  0.4382,\n",
      "        -0.2644, -0.3684,  0.3438, -0.2159, -0.0567, -0.5820,  0.3984, -1.0279,\n",
      "        -0.6783,  0.7477,  0.6121, -0.0264, -0.3678, -0.6593, -0.0404, -0.1783])\n",
      "\n",
      "tensor([ 1.0158,  0.5204,  0.7300,  1.2198,  0.3039,  0.1603, -0.4030,  0.7707,\n",
      "         0.9710, -0.8434,  0.2548, -0.6090,  0.0468,  1.5075, -0.1081,  0.4382,\n",
      "        -0.2644, -0.3684,  0.3438, -0.2159, -0.0567, -0.5820,  0.3984, -1.0279,\n",
      "        -0.6783,  0.7477,  0.6121, -0.0264, -0.3678, -0.6593, -0.0404, -0.1783])\n"
     ]
    }
   ],
   "source": [
    "print('shapes: ', cached_kvs_fs['cache'].shape, cached_kvs_s2['cache'].shape)\n",
    "c_lens = cached_kvs_fs['cache_lengths']\n",
    "mask = torch.arange(c_lens.max())[:,None] < c_lens[None,:]\n",
    "mask = ~mask.T\n",
    "mask = rearrange(mask, 'b i -> () () b () i ()')\n",
    "fs_cache =  cached_kvs_fs['cache'].masked_fill(mask, 0)\n",
    "\n",
    "N = -5\n",
    "L = -1\n",
    "I = 0\n",
    "kv = 1\n",
    "print(fs_cache[L,kv,I,0,N])\n",
    "print()\n",
    "print(cached_kvs_s3['cache'][L,kv,I,0,N])\n",
    "torch.allclose(fs_cache[L,kv,I,0,N], cached_kvs_s3['cache'][L,kv,I,0,N], rtol=0.0001), 'failed custom check'\n",
    "assert torch.allclose(fs_cache, cached_kvs_s3['cache'], rtol=0.01), 'failed full check'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1632), tensor(-0.1632))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_kvs_fs['cache'][L,kv,I,0,N][0], cached_kvs_s2['cache'][L,kv,I,0,N][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 3, 1, 13, 32])\n",
      "torch.Size([10, 2, 3, 1, 13, 32])\n"
     ]
    }
   ],
   "source": [
    "print(cached_kvs_fs['cache'].shape)\n",
    "print(cached_kvs_s2['cache'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3986,  0.3019, -0.9279,  0.2145, -0.5203, -0.1054,  0.1298]) tensor([ 0.3986,  0.3019, -0.9279,  0.2145, -0.5203, -0.1054,  0.1298])\n"
     ]
    }
   ],
   "source": [
    "print(logits_s1[B, :, D], logits_fs[B, :logits_s1.shape[1], D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 11, 11]) torch.Size([1, 1, 11, 11])\n",
      "torch.Size([1, 1, 6, 6]) torch.Size([1, 1, 6, 6])\n",
      "torch.Size([1, 1, 5, 11]) torch.Size([1, 1, 5, 11])\n",
      "tensor([-0.7787, -0.7725, -1.1472, -0.2581,  0.2563]) tensor([-0.7787, -0.7725, -1.1472, -0.2581,  0.2563])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_og, i_logits, cache_kv = model(torch.tensor(tokenizer('/hello bro/')).unsqueeze(0))\n",
    "\n",
    "    x, i_logits, cache_kv = model(torch.tensor(tokenizer('/hello')).unsqueeze(0))\n",
    "    x_c, i_logits, cache_kv = model(torch.tensor(tokenizer(' bro/')).unsqueeze(0), cache=cache_kv)\n",
    "        #print(cache_kv.shape)\n",
    "\n",
    "    #print(x_og.shape, x_c.shape)\n",
    "print(x_og[0,6:, 0], x_c[0,:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  9,  6, 13, 13, 16, 28,  3, 19, 16,  1])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor(tokenizer('/hello')), torch.tensor(tokenizer(' bro/'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 29]) torch.Size([1, 5, 29])\n",
      "tensor([ 0.4475, -0.1402, -0.5746,  0.9537, -1.0230]) tensor([ 0.3507, -0.1993, -0.5755,  0.7726, -1.1193])\n"
     ]
    }
   ],
   "source": [
    "print(x_og.shape, x_c.shape)\n",
    "print(x_og[0,6:, 0], x_c[0,:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(x, length, cache):\n",
    "    x_len = length if length is not None else torch.tensor(x.shape[-2]).expand(x.shape[0])\n",
    "    cache_len = 0 if cache is None else cache['length']\n",
    "    total_len = x_len + cache_len\n",
    "    kv_mask = torch.arange(total_len.max(), device=x.device).expand(len(total_len), -1) >= total_len.unsqueeze(-1)\n",
    "    q_mask = torch.arange(x_len.max(), device=x.device).expand(len(x_len), -1) >= x_len.unsqueeze(-1)\n",
    "    attn_mask = ~(rearrange(~q_mask, \"b n -> b () n ()\") * rearrange(~kv_mask, \"b n -> b () () n\"))\n",
    "\n",
    "    if 1==1: #causal\n",
    "        causal_mask = torch.ones(attn_mask.shape[-2], attn_mask.shape[-1], device=x.device).triu(1 + attn_mask.shape[-2] - attn_mask.shape[-1]).bool()\n",
    "        attn_mask = torch.logical_or(attn_mask, causal_mask)\n",
    "        \n",
    "    return q_mask, attn_mask, x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False, False, False, False, False, False, False, False]]),\n",
       " tensor([[[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True],\n",
       "           [False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "             True,  True,  True,  True,  True]]]]),\n",
       " tensor([10]))"
      ]
     },
     "execution_count": 1161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_masks(x=torch.rand(1, 10,3), length=None, cache={'length': torch.tensor([5])})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
