{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([5, 9, 94, 32, 64]) dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = torch.randn(5, 9, 94, 32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 93, 93, 93],\n",
       "        [ 1,  1,  1,  ..., 92, 92, 92],\n",
       "        [ 2,  2,  2,  ..., 91, 91, 91],\n",
       "        ...,\n",
       "        [91, 91, 91,  ...,  2,  2,  2],\n",
       "        [92, 92, 92,  ...,  1,  1,  1],\n",
       "        [93, 93, 93,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChunkGrid(3008, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    #chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1))\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4792)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "          12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,   23,\n",
       "          24,   25,   26,   27,   28,   29,   30,   31,   32,   33,   34,   35,\n",
       "          36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,   47,\n",
       "          48,   49,   50,   51,   52,   53,   54,   55,   56,   57,   58,   59,\n",
       "          60,   61,   62,   63,   64,   65,   66,   67,   68,   69,   70,   71,\n",
       "          72,   73,   74,   75,   76,   77,   78,   79,   80,   81,   82,   83,\n",
       "          84,   85,   86,   87,   88,   89,   90,   91,   92,   93,   94,   95,\n",
       "          96,   97,   98,   99,  100,  101,  102,  103,  104,  105,  106,  107,\n",
       "         108,  109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
       "         120,  121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "         132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
       "         144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,  155,\n",
       "         156,  157,  158,  159,  160,  161,  162,  163,  164,  165,  166,  167,\n",
       "         168,  169,  170,  171,  172,  173,  174,  175,  176,  177,  178,  179,\n",
       "         180,  181,  182,  183,  184,  185,  186,  187,  188,  189,  190,  191,\n",
       "         192,  193,  194,  195,  196,  197,  198,  199,  200,  201,  202,  203,\n",
       "         204,  205,  206,  207,  208,  209,  210,  211,  212,  213,  214,  215,\n",
       "         216,  217,  218,  219,  220,  221,  222,  223,  224,  225,  226,  227,\n",
       "         228,  229,  230,  231,  232,  233,  234,  235,  236,  237,  238,  239,\n",
       "         240,  241,  242,  243,  244,  245,  246,  247,  248,  249,  250,  251,\n",
       "         252,  253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
       "         264,  265,  266,  267,  268,  269,  270,  272,  273,  274,  275,  276,\n",
       "         278,  279,  280,  281,  283,  284,  286,  287,  289,  290,  293,  294,\n",
       "         298,  301,  302,  304,  305,  306,  307,  308,  309,  314,  315,  316,\n",
       "         317,  318,  319,  320,  322,  323,  324,  325,  326,  327,  328,  329,\n",
       "         332,  335,  338,  340,  341,  342,  343,  344,  345,  346,  347,  351,\n",
       "         353,  358,  363,  370,  371,  374,  379,  382,  387,  390,  398,  400,\n",
       "         404,  431,  432,  433,  444,  453,  460,  467,  483,  486,  495,  503,\n",
       "         543,  565,  579,  585,  593,  594,  607,  616,  653,  655,  703,  710,\n",
       "         734,  756,  776,  815,  829,  889,  939,  945,  946,  950,  958, 1095,\n",
       "        1215, 1242, 1295, 1699, 1780, 2002, 2117, 2154, 2323, 2915, 3209, 4792])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkgrid = ChunkGrid(4800, 48)\n",
    "pareto = torch.distributions.pareto.Pareto(torch.tensor(3.0), torch.tensor(2.0)).sample(chunkgrid.shape)\n",
    "chunkgrid = chunkgrid - pareto\n",
    "\n",
    "column = 0\n",
    "print(chunkgrid[column].topk(384, largest=False).indices.max())\n",
    "chunkgrid[column].topk(384, largest=False).indices.sort(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4800])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkgrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = torch.distributions.pareto.Pareto(3, 2).sample(torch.tensor([100]))\n",
    "plt.hist(dist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4792)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 160,  358,  318, 4792,  246, 3209,  158, 2323,  467, 2915, 1295,    0,\n",
       "          68, 1215, 2154,  945,   54,   11,  946,   47,  275,   67,  950,  137,\n",
       "          60,   84,  102,   72,  157,  114, 1095,  112,  579,  199,  231,  431,\n",
       "         363,  444,  756,  607])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chunkgrid[0].topk(40, largest=False).indices.max())\n",
    "chunkgrid[0].topk(40, largest=False).indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(8, 8).triu(1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias\n",
    "\n",
    "class MyopicAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats,\n",
    "        head_dim,\n",
    "        n_heads,\n",
    "        dropout=0.0,\n",
    "        max_keep_keys=50,\n",
    "        chunk_window=3,\n",
    "        bias=True,\n",
    "        return_attention=False,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_feats = n_feats\n",
    "        self.head_dim = head_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.return_attention = return_attention\n",
    "\n",
    "        self.causal = causal\n",
    "\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.max_keep_keys = max_keep_keys\n",
    "        self.W = chunk_window\n",
    "\n",
    "        self.positional_bias = DynamicPositionBias(\n",
    "            dim = n_feats,\n",
    "            heads = n_heads,\n",
    "            depth = 2,\n",
    "            log_distance = False,\n",
    "            norm = False\n",
    "        )\n",
    "\n",
    "        self.qkv_proj = nn.Linear(n_feats, 3 * n_heads * head_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(n_heads * head_dim, n_feats, bias=bias)\n",
    "\n",
    "    def pad_to_window_size(self, x, window_size, axis=3, mask=None):\n",
    "        \"\"\"\n",
    "        Pad the input on two sides to be divisible by `window_size`\n",
    "        \"\"\"\n",
    "        QKV, batch_size, heads, sequence_length, hidden_size = x.shape\n",
    "        padding_length = (window_size - sequence_length % window_size) % window_size\n",
    "        padding = torch.zeros(QKV, batch_size, heads, padding_length, hidden_size,\n",
    "            device=x.device,\n",
    "            dtype=x.dtype,\n",
    "        )\n",
    "        mask = F.pad(mask, (0, padding_length), value=True) \n",
    "        return torch.cat([x, padding], axis=axis), padding_length, mask\n",
    "\n",
    "    def unpad(self, x, padding_length):\n",
    "        \"\"\"\n",
    "        Undo padding.\n",
    "        \"\"\"\n",
    "        if padding_length > 0:\n",
    "            return x[:, :-padding_length]\n",
    "        return x\n",
    "\n",
    "    def ChunkGrid(self, Total_Size, Block_Size):\n",
    "        Psize = Total_Size // Block_Size\n",
    "        chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "        #chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1)) # don't normalize cus it'll stretch the distribution by sequence length\n",
    "        return chunk_grid    \n",
    "\n",
    "    def causal_windowed_mask(self, window_number, window_size, device):\n",
    "        return torch.ones(window_number, window_number, device=device).triu(1).bool().repeat_interleave(window_size, dim=1)\n",
    "\n",
    "    def forward(self, x, mask, return_attention=False):\n",
    "        assert mask is not None, 'pls wear a mask'\n",
    "        B, N, C, H, D = *x.shape, self.n_heads, self.head_dim\n",
    "\n",
    "        tokeep = min(self.max_keep_keys, N) if self.max_keep_keys != -1 else N # number of keys to keep\n",
    "        W = min(self.W, N) if self.W != -1 else N # window size\n",
    "\n",
    "        qkv = rearrange(self.qkv_proj(x), \"b n (h d qkv) -> qkv b h n d\", qkv=3, h=H, d=D) # qkv projection\n",
    "\n",
    "        qkv, pad_n, mask = self.pad_to_window_size(qkv, W, axis=3, mask=mask) # add padding so it's divisible by W\n",
    "        q, kv = qkv[0], qkv[1:] # separate q and kv, we keep kv together for now as we apply the same operations to both\n",
    "        \n",
    "        q = rearrange(q, \"b h (n w) d -> b h n w d\", w=W)# split q into windows/chunks of size W\n",
    "      \n",
    "        q_mask = repeat(rearrange(mask, \"b (n w) -> b n w\", w=W), \"b n w -> b h n w\", h=H) # do the same for the mask\n",
    "            \n",
    "        kv = repeat(kv, \"kv b h n d -> kv b h nw n d\", nw=q.shape[2]) # duplicate k and v for total number of windows\n",
    "        #print(q.shape, kv.shape)\n",
    "        KV, B, H, NW, N, D = kv.shape\n",
    "\n",
    "        chunkgrid = self.ChunkGrid(Total_Size=N, Block_Size=W).to(q.device)\n",
    "        chunkgrid = repeat(chunkgrid, \"w n -> b h w n\", b=B, h=H).contiguous()\n",
    "\n",
    "        SCALE = torch.tensor(3.0, device=q.device, dtype=q.dtype)\n",
    "        ALPHA = torch.tensor(2.0, device=q.device, dtype=q.dtype)\n",
    "        pareto_dist = torch.distributions.pareto.Pareto(SCALE, ALPHA).sample(chunkgrid.shape).to(q.device)\n",
    "        chunkgrid = chunkgrid - pareto_dist\n",
    "\n",
    "        chunkgrid = repeat(chunkgrid, \"b h w n -> kv b h w n\", kv=2)\n",
    "\n",
    "        cmask = repeat(mask, 'b n -> kv b h nw n', kv=2, h=H, nw=NW)\n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = self.causal_windowed_mask(window_number=NW, window_size=W, device=q.device)\n",
    "            cmask = cmask & causal_mask\n",
    "        \n",
    "        chunkgrid = chunkgrid.masked_fill(cmask, torch.finfo(q.dtype).max) # max cus we topk in reverse order \n",
    "\n",
    "        keep_indices = chunkgrid.topk(k=tokeep, dim=-1, sorted=False, largest=False).indices.sort(dim=-1).values\n",
    "        KV, B, H, NW, N, D = kv.shape \n",
    "        kv = kv.gather(-2, repeat(keep_indices, \"kv b h w n -> kv b h w n d\", d=D))\n",
    "\n",
    "        kv_mask = repeat(mask, \"b n -> b h nw n\", h=H, nw=NW)\n",
    "        if self.causal:\n",
    "            kv_mask = kv_mask & causal_mask \n",
    "        kv_mask = kv_mask.gather(-1, keep_indices[0])\n",
    "\n",
    "        k, v = kv\n",
    "        # nw (number of windows) = p (in the einsum below)\n",
    "        dots = einsum(\"b h n p d, b h n z d -> b h n p z \", q, k) * self.scale # Z is number of chunks in Q, N is max sequence length after dropping\n",
    "\n",
    "        ## positional stuff\n",
    "        pos_bias = self.positional_bias(N, device=dots.device, dtype=dots.dtype)\n",
    "        pos_bias = repeat(pos_bias, 'h i j -> b h i j', b = B)\n",
    "        pos_bias = rearrange(pos_bias, 'b h (n w) j -> b h n w j', w = W)\n",
    "\n",
    "        pos_bias = pos_bias.gather(-1, repeat(keep_indices, \"kv b h nw n -> kv b h nw w n\", w=W)[0])\n",
    "        \n",
    "        dots = dots + pos_bias\n",
    "\n",
    "  \n",
    "        mask_val = -torch.finfo(dots.dtype).max\n",
    "        qk_mask = rearrange(q_mask, \"b h n w -> b h n w ()\") * rearrange(kv_mask, \"b h w n -> b h w () n\")\n",
    "        dots.masked_fill_(qk_mask, mask_val)\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "  \n",
    "        out = einsum(\"b h n w z, b h n z d -> b h n w d\", attn, v)\n",
    "        out = rearrange(out, \"b h n w d -> b (n w) (h d)\")\n",
    "        out = self.unpad(out, pad_n)\n",
    "        out = self.out_proj(out)\n",
    "        return out if not return_attention else (out, attn)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MyopicAttention(n_feats=216, head_dim=24, n_heads=12, max_keep_keys=250, chunk_window=48, causal=True)\n",
    "\n",
    "x = torch.randn(10, 1000, 216)\n",
    "mask = torch.zeros(10, 1000).bool()\n",
    "\n",
    "attn = attention(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1000, 216)\n",
    "mask = torch.zeros(10, 1000).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CHUNKGRID SHIT\n",
    "def ChunkGrid(self, Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1))\n",
    "    return chunk_grid    \n",
    "\n",
    "chunkgrid = repeat(chunkgrid, \"w n -> b h w n\", b=B, h=H).contiguous()\n",
    "MEAN = torch.tensor(0, device=q.device, dtype=q.dtype)\n",
    "STD = torch.tensor(0.125, device=q.device, dtype=q.dtype)\n",
    "uniform_dist = torch.distributions.normal.Normal(MEAN, STD).sample(chunkgrid.shape).to(q.device)\n",
    "chunkgrid += uniform_dist\n",
    "chunkgrid = repeat(chunkgrid, \"b h w n -> kv b h w n\", kv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_windowed_mask(window_number, window_size, device):\n",
    "    mask = torch.ones(window_number, window_number, device=device).triu(1).bool().repeat_interleave(window_size, dim=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_windowed_mask(3, 4, device='cpu').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.indices.sort().values[0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(2).unsqueeze(-1).repeat(2).expand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km[0, 0, :, 0, :100].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.arange(0, 3008).repeat(3008,1) - torch.arange(0, 3008).repeat(3008,1).T).reshape(32, -1, 3008).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- duplicated across KV\n",
    "- each batch, head and Window have a different view of the keys\n",
    "- 94 is the number of windows i.e 94*32(win size) = 3008 (sequence length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv[km].reshape(2, 5, 8, 3, -1, 24).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat(cg, \"W N -> KV B H W N\", B=5, H=8, KV=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(N_BLOCKS, BLOCK_SIZE):\n",
    "    chunk_grid = (torch.arange(0, N_BLOCKS).repeat(BLOCK_SIZE,1) - torch.arange(0, BLOCK_SIZE).repeat(N_BLOCKS,1).T).repeat_interleave(BLOCK_SIZE, dim=1).abs()\n",
    "    chunk_grid = chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1)\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ChunkGrid(41, 3)\n",
    "uniform_dist = torch.distributions.uniform.Uniform(0, 1).sample(cg.shape)\n",
    "cg += uniform_dist\n",
    "keep_indices = cg.topk(9, dim=-1).indices\n",
    "keep_mask = torch.zeros_like(cg).scatter_(1, keep_indices, 1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
