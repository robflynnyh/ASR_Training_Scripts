{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([5, 9, 94, 32, 64]) dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = torch.randn(5, 9, 94, 32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 93, 93, 93],\n",
       "        [ 1,  1,  1,  ..., 92, 92, 92],\n",
       "        [ 2,  2,  2,  ..., 91, 91, 91],\n",
       "        ...,\n",
       "        [91, 91, 91,  ...,  2,  2,  2],\n",
       "        [92, 92, 92,  ...,  1,  1,  1],\n",
       "        [93, 93, 93,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChunkGrid(3008, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    #chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1))\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4446)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "          12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,   23,\n",
       "          24,   25,   26,   27,   28,   29,   30,   31,   32,   33,   34,   35,\n",
       "          36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,   47,\n",
       "          49,   50,   51,   52,   53,   54,   55,   56,   57,   58,   59,   60,\n",
       "          61,   62,   63,   64,   65,   66,   67,   68,   69,   70,   71,   74,\n",
       "          75,   76,   77,   78,   79,   80,   82,   83,   86,   87,   88,   90,\n",
       "          91,   92,   93,   94,   95,   96,   98,  100,  101,  103,  104,  105,\n",
       "         109,  114,  115,  119,  122,  123,  124,  125,  126,  128,  130,  131,\n",
       "         133,  136,  137,  138,  139,  140,  141,  143,  145,  151,  153,  154,\n",
       "         158,  159,  161,  164,  169,  171,  172,  177,  181,  182,  183,  185,\n",
       "         190,  198,  200,  205,  206,  212,  216,  218,  219,  224,  231,  232,\n",
       "         239,  242,  245,  246,  253,  265,  268,  279,  280,  314,  337,  365,\n",
       "         371,  378,  393,  396,  413,  446,  481,  560,  588,  625,  652,  653,\n",
       "         699,  701,  706,  710,  724,  786,  833,  835,  881,  963, 1007, 1011,\n",
       "        1040, 1086, 1119, 1137, 1306, 1421, 1611, 1721, 1739, 1759, 1892, 2093,\n",
       "        2173, 2226, 2366, 2624, 2648, 3243, 4183, 4446])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkgrid = ChunkGrid(4800, 48)\n",
    "pareto = torch.distributions.pareto.Pareto(torch.tensor(3.0), torch.tensor(2.0)).sample(chunkgrid.shape)\n",
    "chunkgrid = chunkgrid - pareto\n",
    "\n",
    "column = 0\n",
    "print(chunkgrid[column].topk(384, largest=False).indices.max())\n",
    "chunkgrid[column].topk(200, largest=False).indices.sort(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4800])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkgrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.0136,  3.0217,  3.0253,  3.0308,  3.0364,  3.0527,  3.0560,  3.0630,\n",
      "         3.0710,  3.0842,  3.1035,  3.1152,  3.1386,  3.1523,  3.1628,  3.1732,\n",
      "         3.1753,  3.1860,  3.2265,  3.2295,  3.2375,  3.3197,  3.3317,  3.3383,\n",
      "         3.3565,  3.3589,  3.3606,  3.3667,  3.4297,  3.4720,  3.4940,  3.5158,\n",
      "         3.5262,  3.5750,  3.6089,  3.6298,  3.6377,  3.6458,  3.6756,  3.7407,\n",
      "         3.7585,  3.8365,  3.9567,  4.0355,  4.1739,  4.2185,  4.3057,  4.3659,\n",
      "         4.3947,  4.4280,  4.4585,  4.4936,  4.5046,  4.5964,  4.7197,  4.7349,\n",
      "         4.8218,  4.9826,  5.0604,  5.1310,  5.1992,  5.4623,  5.6306,  5.7447,\n",
      "         5.7484,  5.7737,  5.8651,  6.0431,  6.0588,  6.1665,  6.2437,  6.3897,\n",
      "         6.4256,  6.4564,  6.6696,  6.8610,  7.0982,  7.1404,  7.2379,  7.4556,\n",
      "         7.9658,  7.9918,  8.2480,  8.9102,  9.3219,  9.3691,  9.9963, 10.0507,\n",
      "        10.1595, 10.8174, 12.6028, 12.9981, 15.0732, 15.1938, 18.5190, 19.3193,\n",
      "        20.1337, 23.7640, 24.2106, 36.2180])\n"
     ]
    }
   ],
   "source": [
    "dist = torch.distributions.pareto.Pareto(3, 2).sample(torch.tensor([100]))\n",
    "plt.hist(dist)\n",
    "plt.show()\n",
    "print(dist.sort(-1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3243)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   9,   13,   20,   24,   40,   49,   63,   96,  114,  123,  137,  143,\n",
       "         154,  169,  198,  219,  231,  232,  314,  337,  365,  560,  701,  710,\n",
       "         786,  835, 1007, 1086, 1137, 1306, 1611, 1721, 1739, 1892, 2093, 2173,\n",
       "        2226, 2366, 2648, 3243])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chunkgrid[0].topk(40, largest=False).indices.max())\n",
    "chunkgrid[0].topk(40, largest=False).indices.sort(-1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(8, 8).triu(1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias\n",
    "\n",
    "class MyopicAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats,\n",
    "        head_dim,\n",
    "        n_heads,\n",
    "        dropout=0.0,\n",
    "        max_keep_keys=50,\n",
    "        chunk_window=3,\n",
    "        bias=True,\n",
    "        return_attention=False,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_feats = n_feats\n",
    "        self.head_dim = head_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.return_attention = return_attention\n",
    "\n",
    "        self.causal = causal\n",
    "\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.max_keep_keys = max_keep_keys\n",
    "        self.W = chunk_window\n",
    "\n",
    "        self.positional_bias = DynamicPositionBias(\n",
    "            dim = n_feats,\n",
    "            heads = n_heads,\n",
    "            depth = 2,\n",
    "            log_distance = False,\n",
    "            norm = False\n",
    "        )\n",
    "\n",
    "        self.qkv_proj = nn.Linear(n_feats, 3 * n_heads * head_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(n_heads * head_dim, n_feats, bias=bias)\n",
    "\n",
    "    def pad_to_window_size(self, x, window_size, axis=3, mask=None):\n",
    "        \"\"\"\n",
    "        Pad the input on two sides to be divisible by `window_size`\n",
    "        \"\"\"\n",
    "        QKV, batch_size, heads, sequence_length, hidden_size = x.shape\n",
    "        padding_length = (window_size - sequence_length % window_size) % window_size\n",
    "        padding = torch.zeros(QKV, batch_size, heads, padding_length, hidden_size,\n",
    "            device=x.device,\n",
    "            dtype=x.dtype,\n",
    "        )\n",
    "        mask = F.pad(mask, (0, padding_length), value=True) \n",
    "        return torch.cat([x, padding], axis=axis), padding_length, mask\n",
    "\n",
    "    def unpad(self, x, padding_length):\n",
    "        \"\"\"\n",
    "        Undo padding.\n",
    "        \"\"\"\n",
    "        if padding_length > 0:\n",
    "            return x[:, :-padding_length]\n",
    "        return x\n",
    "\n",
    "    def ChunkGrid(self, Total_Size, Block_Size):\n",
    "        Psize = Total_Size // Block_Size\n",
    "        chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "        #chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1)) # don't normalize cus it'll stretch the distribution by sequence length\n",
    "        return chunk_grid    \n",
    "\n",
    "    def causal_windowed_mask(self, window_number, window_size, device):\n",
    "        '''\n",
    "        Create a block diagonal causal mask, to prevent selecting future tokens in the topk key selection\n",
    "        '''\n",
    "        return torch.ones(window_number, window_number, device=device).triu(1).bool().repeat_interleave(window_size, dim=1)\n",
    "\n",
    "    def standard_forward(self, qkv, mask):\n",
    "        query, key, value = qkv\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', query, key) * self.scale\n",
    "        positions = self.positional_bias(dots.shape[-1], device=dots.device, dtype=dots.dtype)\n",
    "        dots += positions\n",
    "\n",
    "    \n",
    "        attn_mask = rearrange(mask, 'b n -> b () n ()') & rearrange(mask, 'b m -> b () () m')\n",
    "        \n",
    "\n",
    "        if self.causal:\n",
    "            # create a regular causal mask\n",
    "            causal_mask = torch.ones(dots.shape[-2:], device=dots.device).triu(1).bool()\n",
    "            attn_mask = attn_mask & causal_mask\n",
    "        \n",
    "        dots.masked_fill_(mask, -torch.finfo(dots.dtype).max)\n",
    "        attn = dots.softmax(dim=-1)\n",
    "        return attn \n",
    "\n",
    "\n",
    "    def forward(self, x, mask, return_attention=False):\n",
    "        assert mask is not None, 'pls wear a mask'\n",
    "        B, N, C, H, D = *x.shape, self.n_heads, self.head_dim\n",
    "\n",
    "        tokeep = min(self.max_keep_keys, N) if self.max_keep_keys != -1 else N # number of keys to keep\n",
    "        W = min(self.W, N) if self.W != -1 else N # window size\n",
    "\n",
    "        qkv = rearrange(self.qkv_proj(x), \"b n (h d qkv) -> qkv b h n d\", qkv=3, h=H, d=D) # qkv projection\n",
    "\n",
    "        qkv, pad_n, mask = self.pad_to_window_size(qkv, W, axis=3, mask=mask) # add padding so it's divisible by W\n",
    "        q, kv = qkv[0], qkv[1:] # separate q and kv, we keep kv together for now as we apply the same operations to both\n",
    "        \n",
    "        q = rearrange(q, \"b h (n w) d -> b h n w d\", w=W)# split q into windows/chunks of size W\n",
    "      \n",
    "        q_mask = repeat(rearrange(mask, \"b (n w) -> b n w\", w=W), \"b n w -> b h n w\", h=H) # do the same for the mask\n",
    "            \n",
    "        kv = repeat(kv, \"kv b h n d -> kv b h nw n d\", nw=q.shape[2]) # duplicate k and v for total number of windows\n",
    "        #print(q.shape, kv.shape)\n",
    "        KV, B, H, NW, N, D = kv.shape\n",
    "\n",
    "        chunkgrid = self.ChunkGrid(Total_Size=N, Block_Size=W).to(q.device)\n",
    "        chunkgrid = repeat(chunkgrid, \"w n -> b h w n\", b=B, h=H).contiguous()\n",
    "\n",
    "        SCALE = torch.tensor(3.0, device=q.device, dtype=q.dtype)\n",
    "        ALPHA = torch.tensor(2.0, device=q.device, dtype=q.dtype)\n",
    "        pareto_dist = torch.distributions.pareto.Pareto(SCALE, ALPHA).sample(chunkgrid.shape).to(q.device)\n",
    "        chunkgrid = chunkgrid - pareto_dist\n",
    "\n",
    "        chunkgrid = repeat(chunkgrid, \"b h w n -> kv b h w n\", kv=2)\n",
    "\n",
    "        cmask = repeat(mask, 'b n -> kv b h nw n', kv=2, h=H, nw=NW)\n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = self.causal_windowed_mask(window_number=NW, window_size=W, device=q.device)\n",
    "            cmask = torch.logical_or(cmask, causal_mask)\n",
    "        \n",
    "        chunkgrid = chunkgrid.masked_fill(cmask, torch.finfo(q.dtype).max) # max cus we topk in reverse order \n",
    "\n",
    "        keep_indices = chunkgrid.topk(k=tokeep, dim=-1, sorted=False, largest=False).indices.sort(dim=-1).values\n",
    "        KV, B, H, NW, N, D = kv.shape \n",
    "        kv = kv.gather(-2, repeat(keep_indices, \"kv b h w n -> kv b h w n d\", d=D))\n",
    "\n",
    "        kv_mask = repeat(mask, \"b n -> b h nw n\", h=H, nw=NW)\n",
    "     \n",
    "        kv_mask = kv_mask.gather(-1, keep_indices[0])\n",
    "\n",
    "        k, v = kv\n",
    "        # nw (number of windows) = p (in the einsum below)\n",
    "        dots = einsum(\"b h n p d, b h n z d -> b h n p z \", q, k) * self.scale # Z is number of chunks in Q, N is max sequence length after dropping\n",
    "\n",
    "        ## positional stuff\n",
    "        pos_bias = self.positional_bias(N, device=dots.device, dtype=dots.dtype)\n",
    "        pos_bias = repeat(pos_bias, 'h i j -> b h i j', b = B)\n",
    "        pos_bias = rearrange(pos_bias, 'b h (n w) j -> b h n w j', w = W)\n",
    "\n",
    "        keep_indices = repeat(keep_indices, \"kv b h nw n -> kv b h nw w n\", w=W)[0] \n",
    "        pos_bias = pos_bias.gather(-1, keep_indices)\n",
    "        \n",
    "        dots = dots + pos_bias\n",
    "\n",
    "        mask_val = -torch.finfo(dots.dtype).max\n",
    "        qk_mask = rearrange(q_mask, \"b h n w -> b h n w ()\") * rearrange(kv_mask, \"b h w n -> b h w () n\")\n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = keep_indices > rearrange(torch.arange(0, N, device=q.device), \"(nw w) -> nw w ()\", w=W, nw=NW)\n",
    "            qk_mask = torch.logical_or(qk_mask, causal_mask)\n",
    "    \n",
    "        dots.masked_fill_(qk_mask, mask_val)\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "   \n",
    "  \n",
    "        out = einsum(\"b h n w z, b h n z d -> b h n w d\", attn, v)\n",
    "        out = rearrange(out, \"b h n w d -> b (n w) (h d)\")\n",
    "        out = self.unpad(out, pad_n)\n",
    "        out = self.out_proj(out)\n",
    "        return out if not return_attention else (out, attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MyopicAttention(n_feats=216, head_dim=24, n_heads=12, max_keep_keys=250, chunk_window=48, causal=True)\n",
    "\n",
    "x = torch.randn(10, 1000, 216)\n",
    "mask = torch.zeros(10, 1000).bool()\n",
    "\n",
    "attn = attention(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkm[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1000, 216)\n",
    "mask = torch.zeros(10, 1000).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CHUNKGRID SHIT\n",
    "def ChunkGrid(self, Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1))\n",
    "    return chunk_grid    \n",
    "\n",
    "chunkgrid = repeat(chunkgrid, \"w n -> b h w n\", b=B, h=H).contiguous()\n",
    "MEAN = torch.tensor(0, device=q.device, dtype=q.dtype)\n",
    "STD = torch.tensor(0.125, device=q.device, dtype=q.dtype)\n",
    "uniform_dist = torch.distributions.normal.Normal(MEAN, STD).sample(chunkgrid.shape).to(q.device)\n",
    "chunkgrid += uniform_dist\n",
    "chunkgrid = repeat(chunkgrid, \"b h w n -> kv b h w n\", kv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_windowed_mask(window_number, window_size, device):\n",
    "    mask = torch.ones(window_number, window_number, device=device).triu(1).bool().repeat_interleave(window_size, dim=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True],\n",
       "        [False, False, False, False, False, False, False, False,  True,  True,\n",
       "          True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_windowed_mask(3, 4, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.indices.sort().values[0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(2).unsqueeze(-1).repeat(2).expand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km[0, 0, :, 0, :100].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.arange(0, 3008).repeat(3008,1) - torch.arange(0, 3008).repeat(3008,1).T).reshape(32, -1, 3008).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- duplicated across KV\n",
    "- each batch, head and Window have a different view of the keys\n",
    "- 94 is the number of windows i.e 94*32(win size) = 3008 (sequence length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv[km].reshape(2, 5, 8, 3, -1, 24).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat(cg, \"W N -> KV B H W N\", B=5, H=8, KV=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(N_BLOCKS, BLOCK_SIZE):\n",
    "    chunk_grid = (torch.arange(0, N_BLOCKS).repeat(BLOCK_SIZE,1) - torch.arange(0, BLOCK_SIZE).repeat(N_BLOCKS,1).T).repeat_interleave(BLOCK_SIZE, dim=1).abs()\n",
    "    chunk_grid = chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1)\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ChunkGrid(41, 3)\n",
    "uniform_dist = torch.distributions.uniform.Uniform(0, 1).sample(cg.shape)\n",
    "cg += uniform_dist\n",
    "keep_indices = cg.topk(9, dim=-1).indices\n",
    "keep_mask = torch.zeros_like(cg).scatter_(1, keep_indices, 1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
