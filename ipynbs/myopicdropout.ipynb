{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from torch import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([5, 9, 94, 32, 64]) dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = torch.randn(5, 9, 94, 32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 93, 93, 93],\n",
       "        [ 1,  1,  1,  ..., 92, 92, 92],\n",
       "        [ 2,  2,  2,  ..., 91, 91, 91],\n",
       "        ...,\n",
       "        [91, 91, 91,  ...,  2,  2,  2],\n",
       "        [92, 92, 92,  ...,  1,  1,  1],\n",
       "        [93, 93, 93,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChunkGrid(3008, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    #chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1))\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3611)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "          12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,   23,\n",
       "          24,   25,   26,   27,   28,   29,   30,   31,   32,   33,   34,   35,\n",
       "          36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,   47,\n",
       "          48,   49,   50,   51,   52,   53,   54,   55,   56,   57,   58,   59,\n",
       "          60,   61,   62,   63,   64,   65,   66,   67,   68,   69,   70,   71,\n",
       "          72,   73,   74,   75,   76,   77,   78,   79,   80,   81,   82,   83,\n",
       "          84,   85,   86,   87,   88,   89,   90,   91,   92,   93,   94,   95,\n",
       "          96,   97,   98,   99,  100,  101,  102,  103,  104,  105,  106,  107,\n",
       "         108,  109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
       "         120,  121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "         132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
       "         144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,  155,\n",
       "         156,  157,  158,  159,  160,  161,  162,  163,  164,  165,  166,  167,\n",
       "         168,  169,  170,  171,  172,  173,  174,  175,  176,  177,  178,  179,\n",
       "         180,  181,  182,  183,  184,  185,  186,  187,  188,  189,  190,  191,\n",
       "         192,  193,  194,  195,  196,  197,  198,  199,  200,  201,  202,  203,\n",
       "         204,  205,  206,  207,  208,  209,  210,  211,  212,  213,  214,  215,\n",
       "         216,  217,  218,  219,  220,  221,  222,  223,  224,  225,  226,  227,\n",
       "         228,  229,  230,  231,  232,  233,  234,  235,  236,  237,  238,  239,\n",
       "         240,  242,  243,  244,  245,  246,  247,  249,  250,  251,  252,  253,\n",
       "         255,  256,  257,  258,  259,  260,  261,  262,  264,  266,  269,  271,\n",
       "         272,  273,  274,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
       "         287,  288,  289,  294,  295,  296,  298,  307,  308,  311,  314,  315,\n",
       "         317,  319,  320,  323,  325,  327,  329,  331,  335,  338,  342,  344,\n",
       "         346,  348,  349,  357,  360,  361,  364,  370,  371,  374,  375,  381,\n",
       "         390,  392,  394,  395,  397,  399,  407,  414,  417,  419,  421,  422,\n",
       "         424,  433,  441,  445,  451,  460,  461,  468,  470,  473,  475,  477,\n",
       "         487,  498,  510,  526,  527,  530,  546,  549,  559,  628,  643,  651,\n",
       "         656,  658,  663,  681,  688,  705,  713,  764,  783,  847,  920,  930,\n",
       "         936,  976, 1018, 1020, 1031, 1036, 1085, 1119, 1174, 1224, 1241, 1253,\n",
       "        1268, 1383, 1400, 1409, 1708, 1864, 1916, 2355, 2394, 2398, 3262, 3611])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkgrid = ChunkGrid(4800, 48)\n",
    "pareto = torch.distributions.pareto.Pareto(torch.tensor(3.0), torch.tensor(2.0)).sample(chunkgrid.shape)\n",
    "chunkgrid = chunkgrid - pareto\n",
    "\n",
    "column = 0\n",
    "print(chunkgrid[column].topk(384, largest=False).indices.max())\n",
    "chunkgrid[column].topk(384, largest=False).indices.sort(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4800])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkgrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = torch.distributions.pareto.Pareto(3, 2).sample(torch.tensor([100]))\n",
    "plt.hist(dist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3611)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3262,  628,  920, 1241, 1864,  546, 1400,  104, 1020,  433, 1119, 3611,\n",
       "        1224, 1409, 1268,   14,  651,    6,  289,    4, 1253,   65,   30,  131,\n",
       "         331,  147,  930,  392,   93,  783,   37,   43, 2398,  237,   33,   68,\n",
       "        1708,  287,  510,  349])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chunkgrid[0].topk(40, largest=False).indices.max())\n",
    "chunkgrid[0].topk(40, largest=False).indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(8, 8).triu(1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "class DynamicPositionBias(nn.Module):\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias\n",
    "\n",
    "class MyopicAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats,\n",
    "        head_dim,\n",
    "        n_heads,\n",
    "        dropout=0.0,\n",
    "        max_keep_keys=50,\n",
    "        chunk_window=3,\n",
    "        bias=True,\n",
    "        return_attention=False,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_feats = n_feats\n",
    "        self.head_dim = head_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.return_attention = return_attention\n",
    "\n",
    "        self.causal = causal\n",
    "\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.max_keep_keys = max_keep_keys\n",
    "        self.W = chunk_window\n",
    "\n",
    "        self.positional_bias = DynamicPositionBias(\n",
    "            dim = n_feats,\n",
    "            heads = n_heads,\n",
    "            depth = 2,\n",
    "            log_distance = False,\n",
    "            norm = False\n",
    "        )\n",
    "\n",
    "        self.qkv_proj = nn.Linear(n_feats, 3 * n_heads * head_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(n_heads * head_dim, n_feats, bias=bias)\n",
    "\n",
    "    def pad_to_window_size(self, x, window_size, axis=3, mask=None):\n",
    "        \"\"\"\n",
    "        Pad the input on two sides to be divisible by `window_size`\n",
    "        \"\"\"\n",
    "        QKV, batch_size, heads, sequence_length, hidden_size = x.shape\n",
    "        padding_length = (window_size - sequence_length % window_size) % window_size\n",
    "        padding = torch.zeros(QKV, batch_size, heads, padding_length, hidden_size,\n",
    "            device=x.device,\n",
    "            dtype=x.dtype,\n",
    "        )\n",
    "        mask = F.pad(mask, (0, padding_length), value=True) \n",
    "        return torch.cat([x, padding], axis=axis), padding_length, mask\n",
    "\n",
    "    def unpad(self, x, padding_length):\n",
    "        \"\"\"\n",
    "        Undo padding.\n",
    "        \"\"\"\n",
    "        if padding_length > 0:\n",
    "            return x[:, :-padding_length]\n",
    "        return x\n",
    "\n",
    "    def ChunkGrid(self, Total_Size, Block_Size):\n",
    "        Psize = Total_Size // Block_Size\n",
    "        chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "        #chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1)) # don't normalize cus it'll stretch the distribution by sequence length\n",
    "        return chunk_grid    \n",
    "\n",
    "    def causal_windowed_mask(self, window_number, window_size, device):\n",
    "        '''\n",
    "        Create a block diagonal causal mask, to prevent selecting future tokens in the topk key selection\n",
    "        '''\n",
    "        return torch.ones(window_number, window_number, device=device).triu(1).bool().repeat_interleave(window_size, dim=1)\n",
    "\n",
    "    def forward(self, x, mask, return_attention=False):\n",
    "        assert mask is not None, 'pls wear a mask'\n",
    "        B, N, C, H, D = *x.shape, self.n_heads, self.head_dim\n",
    "\n",
    "        tokeep = min(self.max_keep_keys, N) if self.max_keep_keys != -1 else N # number of keys to keep\n",
    "        W = min(self.W, N) if self.W != -1 else N # window size\n",
    "\n",
    "        qkv = rearrange(self.qkv_proj(x), \"b n (h d qkv) -> qkv b h n d\", qkv=3, h=H, d=D) # qkv projection\n",
    "\n",
    "        qkv, pad_n, mask = self.pad_to_window_size(qkv, W, axis=3, mask=mask) # add padding so it's divisible by W\n",
    "        q, kv = qkv[0], qkv[1:] # separate q and kv, we keep kv together for now as we apply the same operations to both\n",
    "        \n",
    "        q = rearrange(q, \"b h (n w) d -> b h n w d\", w=W)# split q into windows/chunks of size W\n",
    "      \n",
    "        q_mask = repeat(rearrange(mask, \"b (n w) -> b n w\", w=W), \"b n w -> b h n w\", h=H) # do the same for the mask\n",
    "            \n",
    "        kv = repeat(kv, \"kv b h n d -> kv b h nw n d\", nw=q.shape[2]) # duplicate k and v for total number of windows\n",
    "        #print(q.shape, kv.shape)\n",
    "        KV, B, H, NW, N, D = kv.shape\n",
    "\n",
    "        chunkgrid = self.ChunkGrid(Total_Size=N, Block_Size=W).to(q.device)\n",
    "        chunkgrid = repeat(chunkgrid, \"w n -> b h w n\", b=B, h=H).contiguous()\n",
    "\n",
    "        SCALE = torch.tensor(3.0, device=q.device, dtype=q.dtype)\n",
    "        ALPHA = torch.tensor(2.0, device=q.device, dtype=q.dtype)\n",
    "        pareto_dist = torch.distributions.pareto.Pareto(SCALE, ALPHA).sample(chunkgrid.shape).to(q.device)\n",
    "        chunkgrid = chunkgrid - pareto_dist\n",
    "\n",
    "        chunkgrid = repeat(chunkgrid, \"b h w n -> kv b h w n\", kv=2)\n",
    "\n",
    "        cmask = repeat(mask, 'b n -> kv b h nw n', kv=2, h=H, nw=NW)\n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = self.causal_windowed_mask(window_number=NW, window_size=W, device=q.device)\n",
    "            cmask = cmask & causal_mask\n",
    "        \n",
    "        chunkgrid = chunkgrid.masked_fill(cmask, torch.finfo(q.dtype).max) # max cus we topk in reverse order \n",
    "\n",
    "        keep_indices = chunkgrid.topk(k=tokeep, dim=-1, sorted=False, largest=False).indices.sort(dim=-1).values\n",
    "        KV, B, H, NW, N, D = kv.shape \n",
    "        kv = kv.gather(-2, repeat(keep_indices, \"kv b h w n -> kv b h w n d\", d=D))\n",
    "\n",
    "        kv_mask = repeat(mask, \"b n -> b h nw n\", h=H, nw=NW)\n",
    "     \n",
    "        kv_mask = kv_mask.gather(-1, keep_indices[0])\n",
    "\n",
    "        k, v = kv\n",
    "        # nw (number of windows) = p (in the einsum below)\n",
    "        dots = einsum(\"b h n p d, b h n z d -> b h n p z \", q, k) * self.scale # Z is number of chunks in Q, N is max sequence length after dropping\n",
    "\n",
    "        ## positional stuff\n",
    "        pos_bias = self.positional_bias(N, device=dots.device, dtype=dots.dtype)\n",
    "        pos_bias = repeat(pos_bias, 'h i j -> b h i j', b = B)\n",
    "        pos_bias = rearrange(pos_bias, 'b h (n w) j -> b h n w j', w = W)\n",
    "\n",
    "        keep_indices = repeat(keep_indices, \"kv b h nw n -> kv b h nw w n\", w=W)[0] \n",
    "        pos_bias = pos_bias.gather(-1, keep_indices)\n",
    "        \n",
    "        dots = dots + pos_bias\n",
    "\n",
    "        mask_val = -torch.finfo(dots.dtype).max\n",
    "        qk_mask = rearrange(q_mask, \"b h n w -> b h n w ()\") * rearrange(kv_mask, \"b h w n -> b h w () n\")\n",
    "\n",
    "        if self.causal:\n",
    "            causal_mask = keep_indices > rearrange(torch.arange(0, N, device=q.device), \"(nw w) -> nw w ()\", w=W, nw=NW)\n",
    "            qk_mask = qk_mask & causal_mask\n",
    "    \n",
    "        dots.masked_fill_(qk_mask, mask_val)\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "  \n",
    "        out = einsum(\"b h n w z, b h n z d -> b h n w d\", attn, v)\n",
    "        out = rearrange(out, \"b h n w d -> b (n w) (h d)\")\n",
    "        out = self.unpad(out, pad_n)\n",
    "        out = self.out_proj(out)\n",
    "        return out if not return_attention else (out, attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MyopicAttention(n_feats=216, head_dim=24, n_heads=12, max_keep_keys=250, chunk_window=48, causal=True)\n",
    "\n",
    "x = torch.randn(10, 1000, 216)\n",
    "mask = torch.zeros(10, 1000).bool()\n",
    "\n",
    "attn = attention(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1000, 216)\n",
    "mask = torch.zeros(10, 1000).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CHUNKGRID SHIT\n",
    "def ChunkGrid(self, Total_Size, Block_Size):\n",
    "    Psize = Total_Size // Block_Size\n",
    "    chunk_grid = (torch.arange(0, Psize).repeat(Psize,1) - torch.arange(0, Psize).repeat(Psize,1).T ).repeat_interleave(Block_Size, dim=1).abs()\n",
    "    chunk_grid = 1 - (chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1))\n",
    "    return chunk_grid    \n",
    "\n",
    "chunkgrid = repeat(chunkgrid, \"w n -> b h w n\", b=B, h=H).contiguous()\n",
    "MEAN = torch.tensor(0, device=q.device, dtype=q.dtype)\n",
    "STD = torch.tensor(0.125, device=q.device, dtype=q.dtype)\n",
    "uniform_dist = torch.distributions.normal.Normal(MEAN, STD).sample(chunkgrid.shape).to(q.device)\n",
    "chunkgrid += uniform_dist\n",
    "chunkgrid = repeat(chunkgrid, \"b h w n -> kv b h w n\", kv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_windowed_mask(window_number, window_size, device):\n",
    "    mask = torch.ones(window_number, window_number, device=device).triu(1).bool().repeat_interleave(window_size, dim=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True],\n",
       "        [False, False, False, False, False, False, False, False,  True,  True,\n",
       "          True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_windowed_mask(3, 4, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.indices.sort().values[0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(2).unsqueeze(-1).repeat(2).expand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km[0, 0, :, 0, :100].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.arange(0, 3008).repeat(3008,1) - torch.arange(0, 3008).repeat(3008,1).T).reshape(32, -1, 3008).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- duplicated across KV\n",
    "- each batch, head and Window have a different view of the keys\n",
    "- 94 is the number of windows i.e 94*32(win size) = 3008 (sequence length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv[km].reshape(2, 5, 8, 3, -1, 24).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat(cg, \"W N -> KV B H W N\", B=5, H=8, KV=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChunkGrid(N_BLOCKS, BLOCK_SIZE):\n",
    "    chunk_grid = (torch.arange(0, N_BLOCKS).repeat(BLOCK_SIZE,1) - torch.arange(0, BLOCK_SIZE).repeat(N_BLOCKS,1).T).repeat_interleave(BLOCK_SIZE, dim=1).abs()\n",
    "    chunk_grid = chunk_grid / chunk_grid.max(dim=-1)[0].unsqueeze(-1)\n",
    "    return chunk_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ChunkGrid(41, 3)\n",
    "uniform_dist = torch.distributions.uniform.Uniform(0, 1).sample(cg.shape)\n",
    "cg += uniform_dist\n",
    "keep_indices = cg.topk(9, dim=-1).indices\n",
    "keep_mask = torch.zeros_like(cg).scatter_(1, keep_indices, 1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
