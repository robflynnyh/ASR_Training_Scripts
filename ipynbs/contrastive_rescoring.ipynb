{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/exp1/acp21rjf/deliberation/speachy\n",
      "ami\t\t    log.txt\t\t   speachy.egg-info\n",
      "checkpoints\t    model_configs\t   sweep_configs\n",
      "checkpoints_done    model_utils.py\t   sweep.yaml\n",
      "experiment_configs  mwer_rescoring.py\t   tedlium\n",
      "hyps\t\t    non_iid_dataloader.py  tools.py\n",
      "ipynbs\t\t    pg191kwft.json\t   top100_5kb_history_250.pkl\n",
      "IS_30s_utt.json     __pycache__\t\t   train_LM.py\n",
      "IS_single_utt\t    README.md\t\t   train_lm.sh\n",
      "lm\t\t    setup.py\t\t   wandb\n",
      "lm_utils.py\t    speachy\t\t   wip\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-01-25 11:41:10 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-01-25 11:41:10 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl, numpy as np\n",
    "from speachy.rescoring.tools import (\n",
    "        sort_hypothesis_by_recording, \n",
    "        order_recordings_by_start_time,\n",
    "        interpolate\n",
    ")\n",
    "from functools import partial, reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hyps/test_beams_5000.pkl', 'rb') as f:\n",
    "    test_beams = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_beams = order_recordings_by_start_time(sort_hypothesis_by_recording(test_beams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distance(hyps, target):\n",
    "    return list(map(lambda x: distance(x, target) / len(target), hyps))\n",
    "    \n",
    "def create_samples_from_recording(recording, num_utterances, num_negatives, max_gap=10.0, shuffle=True):\n",
    "    samples = []\n",
    "    prev_end = None\n",
    "    if shuffle == False:\n",
    "        np.random.seed(42) # deterministic selection of negatives\n",
    "    for i, utterance in enumerate(recording):\n",
    "        start_t, end_t = utterance['meta_data']['timings'].values()\n",
    "        if prev_end is None or (start_t - prev_end) > max_gap:\n",
    "            samples.append([]) \n",
    "        if len(samples[-1]) >= num_utterances:\n",
    "            samples.append([])\n",
    "        hyps = utterance['beams'][0]\n",
    "        hyps = list(map(lambda x: x['text'], list(hyps.values())))\n",
    "        target = utterance['targets'][0]\n",
    "        hyps = list(filter(lambda el:el != target, hyps))\n",
    "        hyps = np.random.choice(hyps, min(num_negatives, len(hyps)), replace=False).tolist()\n",
    "        examples = [target] + hyps\n",
    "        error_rates = get_edit_distance(examples, target)\n",
    "        samples[-1].append((examples, error_rates))\n",
    "        prev_end = end_t\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_samples(recordings, num_utterances, num_negatives, max_gap=10.0, shuffle=True):\n",
    "    samples = []\n",
    "    for recording in recordings.keys():\n",
    "        samples += create_samples_from_recording(recordings[recording], num_utterances, num_negatives, max_gap, shuffle)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(samples) # shuffle samples\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_pad(utterances, tokenizer):\n",
    "    tokenized = [tokenizer.text_to_ids(utt) for utt in utterances]\n",
    "    max_len = max(map(len, tokenized))\n",
    "    return np.array([utt + [0] * (max_len - len(utt)) for utt in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_nested_list = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_batches(batch, tokenizer):\n",
    "    proc_utts = lambda utts: tokenize_and_pad(flatten_nested_list(utts), tokenizer)\n",
    "    sub_batches = []\n",
    "    max_len = max(map(len, batch))\n",
    "    for i in range(max_len):\n",
    "        sub_batches.append({\n",
    "            'utterances': [],\n",
    "            'scores': [],\n",
    "            'lengths': [],\n",
    "        })\n",
    "        for el in batch:\n",
    "            if len(el) > i:\n",
    "                sub_batches[-1]['utterances'].append(el[i][0])\n",
    "                sub_batches[-1]['scores'].append(el[i][1])\n",
    "                sub_batches[-1]['lengths'].append(len(el[i][0]))\n",
    "            else:\n",
    "                sub_batches[-1]['utterances'].append(-1)\n",
    "                sub_batches[-1]['scores'].append(-1)\n",
    "                sub_batches[-1]['lengths'].append(-1)\n",
    "    non_empty_indices = np.arange(len(sub_batches[0]['lengths']))\n",
    "\n",
    "    for i, sub_batch in enumerate(sub_batches):\n",
    "        sb_utts, sb_scores, sb_lengths = np.array(sub_batch['utterances'], dtype=object), \\\n",
    "            np.array(sub_batch['scores'], dtype=object), np.array(sub_batch['lengths'], dtype=object)\n",
    "        non_empty = non_empty_indices[sb_lengths != -1]\n",
    "        # slice based on non empty of previous sub batch\n",
    "        prev_fetch = None\n",
    "        if i != 0:\n",
    "            prev_lengths = sub_batches[i-1]['lengths']\n",
    "            prev_non_empty = sub_batches[i-1]['non_empty']\n",
    "            diff_from = ((prev_lengths != -1) == (sb_lengths != -1))[prev_non_empty]\n",
    "            prev_fetch = np.arange(len(prev_non_empty))[diff_from]\n",
    "        sub_batches[i] = {\n",
    "            'utterances': sb_utts,\n",
    "            'scores': sb_scores,\n",
    "            'lengths': sb_lengths,\n",
    "            'non_empty': non_empty,\n",
    "            'prev_fetch': prev_fetch \n",
    "        }\n",
    "    \n",
    "    for i, sub_batch in enumerate(sub_batches):\n",
    "        sub_batches[i] = {\n",
    "            'utterances': proc_utts(sub_batch['utterances'][sub_batch['non_empty']].tolist()),\n",
    "            'scores': sub_batch['scores'][sub_batch['non_empty']],\n",
    "            'lengths': sub_batch['lengths'][sub_batch['non_empty']],\n",
    "            'prev_fetch': sub_batch['prev_fetch'] # indices to fetch the states from previous sub batch\n",
    "        }\n",
    "    return sub_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(samples, batch_size, tokenizer, shuffle=True):\n",
    "    sample_indices = np.arange(len(samples))\n",
    "    np.random.shuffle(sample_indices) if shuffle else None\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        yield get_sub_batches([samples[i] for i in sample_indices[i:i+batch_size]], tokenizer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_list = [[utt[0] for utt in utt_in_batch] for utt_in_batch in s1]\n",
    "score_list = [[utt[1] for utt in utt_in_batch] for utt_in_batch in s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_nested_list = lambda lst: reduce(lambda x,y: x+y, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_217678/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1012350713.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_217678/1012350713.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'non_empty'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_217678/\u001b[0m\u001b[1;33m1012350713.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_217678/1012350713.py'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'non_empty'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbs[-40]['non_empty'] == sbs[-39]['non_empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-01-24 17:34:20 nemo_logging:349] /tmp/ipykernel_217678/3944724721.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "      np.arange(9) == np.arange(3)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(9) == np.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "ix = -2\n",
    "print(sbs[ix]['lengths'])\n",
    "print(len(sbs[ix]['utterances']))\n",
    "print(sbs[ix]['prev_fetch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1[0]['utterances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = tools.load_tokenizer('./tedlium/tokenizers/tokenizer_spe_bpe_v1000/tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_pad(utterances, tokenizer):\n",
    "    tokenized = [tokenizer.text_to_ids(utt) for utt in utterances]\n",
    "    max_len = max(map(len, tokenized))\n",
    "    return np.array([utt + [0] * (max_len - len(utt)) for utt in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_552617/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4219463649.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_552617/4219463649.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'tcol'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_552617/\u001b[0m\u001b[1;33m4219463649.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_552617/4219463649.py'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'tcol'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tcol(cuts=None,text=(s1[0]['utterances'][-5], s1[0]['utterances'][-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-01-24 17:33:01 nemo_logging:349] /tmp/ipykernel_217678/3555533298.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "      np.array([['f','z'],['helo']]).tolist()\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['f', 'z'], ['helo']]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([['f','z'],['helo']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[2]['utterances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41, 440, 103, 158,   4, 279, 448,   6, 350,  53, 170,   4, 279,\n",
       "        16,  53,  27, 438, 106, 217, 987,  20,   4, 279, 351,  37,  42,\n",
       "       146, 104, 299,   5, 208, 979, 125,   4, 304,  34,  60, 293, 973,\n",
       "       482,  20, 102,   6, 759,  33,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1[0]['utterances'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = next(sampler(samples, 5, tk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = create_dataset_samples(test_beams, num_negatives=5, num_utterances=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my the sars handy never a' writing anything but\",\n",
       "       \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my theisarres handy never im writing anything but\",\n",
       "       \"i'd like to share with you a discovery that i made a few months ago while writing an article for italian wired i always keep my the sars handy never are and writing anything but\",\n",
       "       \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my f the sars handy never ionm writing anything but\",\n",
       "       \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my the sarres handy i never a writing anything but\"],\n",
       "      dtype='<U188')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = list(map(lambda el:el['text'],list(test_beams['AimeeMullins_2009P'][0]['beams'][0].values())))\n",
    "target = test_beams['AimeeMullins_2009P'][0]['targets'][0]\n",
    "hyps = list(filter(lambda el:el != target, hyps))\n",
    "# select 5 random hyps\n",
    "hyps = np.random.choice(hyps, min(5, len(hyps)), replace=False).tolist()\n",
    "hyps = hyps + [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.096045197740113,\n",
       "  \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my f sars handy i've never writing anything but\"),\n",
       " (0.0903954802259887,\n",
       "  \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my the f sars handy i never writing anything but\"),\n",
       " (0.1016949152542373,\n",
       "  \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my f the sars handy i never i a and writing anything but\"),\n",
       " (0.096045197740113,\n",
       "  \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my th the sars handy i never writing anything but\"),\n",
       " (0.06779661016949153,\n",
       "  \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my the sars handym never im writing anything but\"),\n",
       " (0.0,\n",
       "  \"i'd like to share with you a discovery that i made a few months ago while writing an article for italian wired i always keep my thesaurus handy whenever i'm writing anything but\")]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(get_edit_distance(hyps, target), hyps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0753)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(get_edit_distance(hyps, target))).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0207,  0.0151,  0.0264,  0.0207, -0.0075, -0.0753])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(get_edit_distance(hyps, target))) - (torch.tensor(get_edit_distance(hyps, target))).mean(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
