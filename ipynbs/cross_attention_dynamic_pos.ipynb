{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "class DynamicPositionBias(nn.Module):\n",
    "    '''taken From Phil Wang's x-transformers library'''\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, n, device, dtype):\n",
    "\n",
    "        # get the (n x n) matrix of distances\n",
    "        seq_arange = torch.arange(n, device = device)\n",
    "        context_arange = torch.arange(n, device = device)\n",
    "        indices = rearrange(seq_arange, 'i -> i 1') - rearrange(context_arange, 'j -> 1 j')\n",
    "        indices += (n - 1)\n",
    "        \n",
    "        # input to continuous positions MLP\n",
    "        pos = torch.arange(-n + 1, n, device = device, dtype = dtype)\n",
    "        pos = rearrange(pos, '... -> ... 1')\n",
    "        print(pos.shape)\n",
    "\n",
    "        if self.log_distance:\n",
    "            pos = torch.sign(pos) * torch.log(pos.abs() + 1)  # log of distance is sign(rel_pos) * log(abs(rel_pos) + 1)\n",
    "\n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        # get position biases        \n",
    "        bias = pos[indices]\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "        return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicNSPPositionBias(nn.Module):\n",
    "    '''Adapted From Phil Wang's x-transformers library for specific case of cross-attention'''\n",
    "    def __init__(self, dim, *, heads, depth, log_distance = False, norm = False):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, 'depth for dynamic position bias MLP must be greater or equal to 1'\n",
    "        self.log_distance = log_distance\n",
    "\n",
    "        self.mlp = nn.ModuleList([])\n",
    "\n",
    "        self.mlp.append(nn.Sequential(\n",
    "            nn.Linear(1, dim),\n",
    "            nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            self.mlp.append(nn.Sequential(\n",
    "                nn.Linear(dim, dim),\n",
    "                nn.LayerNorm(dim) if norm else nn.Identity(),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "\n",
    "        self.mlp.append(nn.Linear(dim, heads))\n",
    "\n",
    "    def forward(self, qn, kn, device, dtype): # set dtype and device to the same as q and k\n",
    "\n",
    "        # get the (qn x kn) matrix of distances\n",
    "        seq_arange = torch.arange(kn, device = device, dtype = torch.long) - kn # -kn ... -1\n",
    "        seq_arange = repeat(seq_arange, 'k -> q k', q = qn) # repeat for each query\n",
    "        seq_arange = seq_arange - torch.arange(qn, device = device, dtype = torch.long).unsqueeze(-1) # matrix of relative distance between query and keys\n",
    "        \n",
    "        minval = -(kn - 1) - (qn - 1) - 1 # extra -1 cus we start at -1\n",
    "        seq_arange -= minval # shift to positive values to use for indexing\n",
    "\n",
    "        pos = torch.arange(minval, 0, device = device, dtype = dtype).unsqueeze(-1)\n",
    "      \n",
    "        for layer in self.mlp:\n",
    "            pos = layer(pos)\n",
    "\n",
    "        bias = pos[seq_arange]\n",
    "        \n",
    "        return rearrange(bias, 'qn kn h -> h qn kn') # add this to dot product of q and k\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = 512\n",
    "n_heads = 8\n",
    "dpos = DynamicNSPPositionBias(\n",
    "    dim = dim_model // 4,\n",
    "    heads = n_heads,\n",
    "    depth = 2,\n",
    "    log_distance = False,\n",
    "    norm = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-146., -145., -144., -143., -142., -141., -140., -139., -138., -137.,\n",
       "        -136., -135., -134., -133., -132., -131., -130., -129., -128., -127.,\n",
       "        -126., -125., -124., -123., -122., -121., -120., -119., -118., -117.,\n",
       "        -116., -115., -114., -113., -112., -111., -110., -109., -108., -107.,\n",
       "        -106., -105., -104., -103., -102., -101., -100.,  -99.,  -98.,  -97.,\n",
       "         -96.,  -95.,  -94.,  -93.,  -92.,  -91.,  -90.,  -89.,  -88.,  -87.,\n",
       "         -86.,  -85.,  -84.,  -83.,  -82.,  -81.,  -80.,  -79.,  -78.,  -77.,\n",
       "         -76.,  -75.,  -74.,  -73.,  -72.,  -71.,  -70.,  -69.,  -68.,  -67.,\n",
       "         -66.,  -65.,  -64.,  -63.,  -62.,  -61.,  -60.,  -59.,  -58.,  -57.,\n",
       "         -56.,  -55.,  -54.,  -53.,  -52.,  -51.,  -50.,  -49.,  -48.,  -47.,\n",
       "         -46.,  -45.,  -44.,  -43.,  -42.,  -41.,  -40.,  -39.,  -38.,  -37.,\n",
       "         -36.,  -35.,  -34.,  -33.,  -32.,  -31.,  -30.,  -29.,  -28.,  -27.,\n",
       "         -26.,  -25.,  -24.,  -23.,  -22.,  -21.,  -20.,  -19.,  -18.,  -17.,\n",
       "         -16.,  -15.,  -14.,  -13.,  -12.,  -11.,  -10.,   -9.,   -8.,   -7.,\n",
       "          -6.,   -5.,   -4.,   -3.,   -2.,   -1.,    0.,    1.,    2.,    3.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.squeeze()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (150) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m qn, kn \u001b[38;5;241m=\u001b[39m dots\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m      6\u001b[0m pos \u001b[38;5;241m=\u001b[39m dpos(qn, kn, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m# position bias only needs to be calculated once and can be reused for all layers\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m dots \u001b[38;5;241m=\u001b[39m dots \u001b[38;5;241m+\u001b[39m pos\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (150) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "q = torch.randn(10, 8, 30, 32)\n",
    "k = torch.randn(10, 8, 150, 32)\n",
    "\n",
    "dots = torch.einsum('b h i d, b h j d -> b h i j', q, k) # cross attention for dot product\n",
    "qn, kn = dots.shape[-2:]\n",
    "pos = dpos(qn, kn, device='cpu', dtype=torch.float32) # position bias only needs to be calculated once and can be reused for all layers\n",
    "dots = dots + pos # POSITIONIFIED \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
