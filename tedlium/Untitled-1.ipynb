{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-15 11:43:26 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-11-15 11:43:28 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-11-15 11:43:28 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-11-15 11:43:28 nemo_logging:349] /exp/exp1/acp21rjf/lhotse/lhotse/lazy.py:388: UserWarning: A lambda was passed to LazyMapper: it may prevent you from forking this process. If you experience issues with num_workers > 0 in torch.utils.data.DataLoader, try passing a regular function instead.\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "corpus = tools.load_corpus()\n",
    "import pickle as pkl\n",
    "from importlib import reload as rl\n",
    "import non_iid_dataloader as niiddl, lhotse\n",
    "from tqdm import tqdm\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer, Transformer\n",
    "import torch\n",
    "from omegaconf.omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import einops\n",
    "from torch import einsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_qknorm_60s_inter_50do_128  model_utils.py\n",
      "checkpoint_qknorm_ctx_temp\t      ngrams\n",
      "checkpoint_qknorm_hierarchy_do50      non_iid_dataloader.py\n",
      "create_tokenizer\t\t      plain_text\n",
      "eval_ctc_h_init.py\t\t      __pycache__\n",
      "eval_ctc_reuse.py\t\t      tokenizers\n",
      "eval_perplexity_pretrained.py\t      tools.py\n",
      "eval_perplexity.py\t\t      train_H.py\n",
      "generate_multi_hypothesis.py\t      train_LM.py\n",
      "hypothesis.pkl\t\t\t      train_lm.sh\n",
      "lm\t\t\t\t      train_long_context.sh\n",
      "lm_exps\t\t\t\t      train_roberta.sh\n",
      "lm_utils.py\t\t\t      Untitled-1.ipynb\n",
      "log_probs_0.pkl\t\t\t      wandb\n",
      "log.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log_probs_0.pkl', 'rb') as f:\n",
    "    log_probs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = tools.load_tokenizer('./tokenizers/tokenizer_spe_bpe_v128/tokenizer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload as rl\n",
    "rl(model_utils)\n",
    "rl(niiddl)\n",
    "import non_iid_dataloader as niiddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "def kenlm_decoder(arpa_, vocab, alpha=0.5, beta=0.8):  \n",
    "    arpa = arpa_ if arpa_ != '' else None\n",
    "    alpha = alpha if arpa_ != '' else None\n",
    "    beta = beta if arpa_ != '' else None\n",
    "    decoder = build_ctcdecoder(vocab, kenlm_model_path=arpa, alpha=alpha, beta=beta)\n",
    "    print(f'Loaded KenLM model from {arpa} with alpha={alpha} and beta={beta}')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /exp/exp1/acp21rjf/deliberation/speachy/tedlium/ngrams/cantab_interp_tedlium.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigrams and labels don't seem to agree.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded KenLM model from ./ngrams/cantab_interp_tedlium.arpa with alpha=0.5 and beta=0.8\n"
     ]
    }
   ],
   "source": [
    "lm = kenlm_decoder('./ngrams/cantab_interp_tedlium.arpa', tk.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['log_probs', 'decoder', 'encoded_len'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[275]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs['encoded_len'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeams = model_utils.decode_beams_lm(logits_list=log_probs['log_probs'], decoder=lm, encoded_lengths=log_probs['encoded_len'].tolist(), beam_width=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = niiddl.get_eval_dataloader(corpus['test'], max_duration=3.0, return_speaker=True, return_meta_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in dl:\n",
    "    a = z\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'metadata'"
     ]
    }
   ],
   "source": [
    "a['metadata'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.metrics.wer import word_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hypothesis.pkl', 'rb') as f:\n",
    "    hypothesis = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_hypothesis_by_recording(hyps):\n",
    "    recordings = {}\n",
    "    for hyp in hyps:\n",
    "        rec = hyp['meta_data']['recording_id']\n",
    "        if rec not in recordings:\n",
    "            recordings[rec] = []\n",
    "        recordings[rec].append(hyp)\n",
    "    return recordings\n",
    "\n",
    "def order_recordings_by_start_time(hypothesis):\n",
    "    for key in hypothesis.keys():\n",
    "        hypothesis[key] = sorted(hypothesis[key], key=lambda x: x['meta_data']['timings']['segment_start'])\n",
    "    return hypothesis\n",
    "\n",
    "def get_oracle_wer(hypothesis):\n",
    "    hyps, refs = [], []\n",
    "    for key in hypothesis.keys():\n",
    "        recording = hypothesis[key]\n",
    "        for utt in tqdm(recording):\n",
    "            best_idx, best_score = None, None\n",
    "            target = utt['targets'][0]\n",
    "            for idx in utt['beams'][0].keys():\n",
    "                cur = utt['beams'][0][idx]\n",
    "                hyptext = cur['text']\n",
    "                hypwer = word_error_rate([hyptext], [target])\n",
    "                if best_idx is None or hypwer < best_score:\n",
    "                    best_idx = idx\n",
    "                    best_score = hypwer\n",
    "            hyps.append(utt['beams'][0][best_idx]['text'])\n",
    "            refs.append(target)\n",
    "    return word_error_rate(hyps, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sort_hypothesis_by_recording(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = order_recordings_by_start_time(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AimeeMullins_2009P', 'EricMead_2009P', 'MichaelSpecter_2010', 'GaryFlake_2010', 'DanBarber_2010', 'DanielKahneman_2010', 'BillGates_2010', 'RobertGupta_2010U', 'JaneMcGonigal_2010', 'JamesCameron_2010', 'TomWujec_2010U'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5114, dtype=torch.float64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a['AimeeMullins_2009P'][1]['beams'][0][0]['score']).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "v,b =a['AimeeMullins_2009P'][1]['meta_data']['timings'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:00<00:00, 609.04it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 434.42it/s]\n",
      "100%|██████████| 124/124 [00:00<00:00, 555.79it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 430.03it/s]\n",
      "100%|██████████| 236/236 [00:00<00:00, 1290.78it/s]\n",
      "100%|██████████| 138/138 [00:00<00:00, 636.12it/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 540.98it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 485.14it/s]\n",
      "100%|██████████| 108/108 [00:00<00:00, 420.77it/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 463.45it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 422.69it/s]\n"
     ]
    }
   ],
   "source": [
    "o = get_oracle_wer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_error_rate(['hello'],['bye'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"i'd like to share with you a discovery that i made a few months ago while writing an article for the italian wired i always keep my the sars hand never'm writing anything but\",\n",
       " 'score': -5.665437203736285}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['AimeeMullins_2009P'][0]['beams'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings = niiddl.prepare_partition(corpus['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lhotse\n",
    "import non_iid_dataloader as niiddl\n",
    "rl(niiddl),rl(lhotse)\n",
    "from lhotse.dataset.collation import collate_audio\n",
    "from lhotse.dataset.cut_transforms import plain_concat, individual_speaker_concat\n",
    "niiddl.plain_concat = plain_concat\n",
    "niiddl.individual_speaker_concat = individual_speaker_concat\n",
    "\n",
    "samples = niiddl.prepare_samples(meetings, max_allowed_utterance_gap=8.0, max_duration=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl(lm_utils)\n",
    "model = lm_utils.load_model(lm_utils.load_config('./lm/decoder_test.yaml'), tools.load_tokenizer(), max_len=1862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lm(\n",
       "  (layers): transformer(\n",
       "    (positional_bias): DynamicPositionBias(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=64, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_logits): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (embedding): Embedding(128, 256)\n",
       "  (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'checkpoints_LM3': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints_LM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>,\n",
       " <module 'model_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/model_utils.py'>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(lm_utils), rl(model_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint_myopic_test/checkpoint_11_id_18.pt\n",
      "odict_keys(['layers.positional_bias.mlp.0.0.weight', 'layers.positional_bias.mlp.0.0.bias', 'layers.positional_bias.mlp.1.0.weight', 'layers.positional_bias.mlp.1.0.bias', 'layers.positional_bias.mlp.2.weight', 'layers.positional_bias.mlp.2.bias', 'layers.layers.0.0.norm.weight', 'layers.layers.0.0.norm.bias', 'layers.layers.0.0.fn.qkv_proj.weight', 'layers.layers.0.0.fn.out_proj.weight', 'layers.layers.0.1.norm.weight', 'layers.layers.0.1.norm.bias', 'layers.layers.0.1.fn.0.proj.weight', 'layers.layers.0.1.fn.0.proj.bias', 'layers.layers.0.1.fn.2.weight', 'layers.layers.0.1.fn.2.bias', 'layers.layers.1.0.norm.weight', 'layers.layers.1.0.norm.bias', 'layers.layers.1.0.fn.qkv_proj.weight', 'layers.layers.1.0.fn.out_proj.weight', 'layers.layers.1.1.norm.weight', 'layers.layers.1.1.norm.bias', 'layers.layers.1.1.fn.0.proj.weight', 'layers.layers.1.1.fn.0.proj.bias', 'layers.layers.1.1.fn.2.weight', 'layers.layers.1.1.fn.2.bias', 'layers.layers.2.0.norm.weight', 'layers.layers.2.0.norm.bias', 'layers.layers.2.0.fn.qkv_proj.weight', 'layers.layers.2.0.fn.out_proj.weight', 'layers.layers.2.1.norm.weight', 'layers.layers.2.1.norm.bias', 'layers.layers.2.1.fn.0.proj.weight', 'layers.layers.2.1.fn.0.proj.bias', 'layers.layers.2.1.fn.2.weight', 'layers.layers.2.1.fn.2.bias', 'layers.layers.3.0.norm.weight', 'layers.layers.3.0.norm.bias', 'layers.layers.3.0.fn.qkv_proj.weight', 'layers.layers.3.0.fn.out_proj.weight', 'layers.layers.3.1.norm.weight', 'layers.layers.3.1.norm.bias', 'layers.layers.3.1.fn.0.proj.weight', 'layers.layers.3.1.fn.0.proj.bias', 'layers.layers.3.1.fn.2.weight', 'layers.layers.3.1.fn.2.bias', 'layers.layers.4.0.norm.weight', 'layers.layers.4.0.norm.bias', 'layers.layers.4.0.fn.qkv_proj.weight', 'layers.layers.4.0.fn.out_proj.weight', 'layers.layers.4.1.norm.weight', 'layers.layers.4.1.norm.bias', 'layers.layers.4.1.fn.0.proj.weight', 'layers.layers.4.1.fn.0.proj.bias', 'layers.layers.4.1.fn.2.weight', 'layers.layers.4.1.fn.2.bias', 'layers.layers.5.0.norm.weight', 'layers.layers.5.0.norm.bias', 'layers.layers.5.0.fn.qkv_proj.weight', 'layers.layers.5.0.fn.out_proj.weight', 'layers.layers.5.1.norm.weight', 'layers.layers.5.1.norm.bias', 'layers.layers.5.1.fn.0.proj.weight', 'layers.layers.5.1.fn.0.proj.bias', 'layers.layers.5.1.fn.2.weight', 'layers.layers.5.1.fn.2.bias', 'layers.layers.6.0.norm.weight', 'layers.layers.6.0.norm.bias', 'layers.layers.6.0.fn.qkv_proj.weight', 'layers.layers.6.0.fn.out_proj.weight', 'layers.layers.6.1.norm.weight', 'layers.layers.6.1.norm.bias', 'layers.layers.6.1.fn.0.proj.weight', 'layers.layers.6.1.fn.0.proj.bias', 'layers.layers.6.1.fn.2.weight', 'layers.layers.6.1.fn.2.bias', 'layers.layers.7.0.norm.weight', 'layers.layers.7.0.norm.bias', 'layers.layers.7.0.fn.qkv_proj.weight', 'layers.layers.7.0.fn.out_proj.weight', 'layers.layers.7.1.norm.weight', 'layers.layers.7.1.norm.bias', 'layers.layers.7.1.fn.0.proj.weight', 'layers.layers.7.1.fn.0.proj.bias', 'layers.layers.7.1.fn.2.weight', 'layers.layers.7.1.fn.2.bias', 'layers.layers.8.0.norm.weight', 'layers.layers.8.0.norm.bias', 'layers.layers.8.0.fn.qkv_proj.weight', 'layers.layers.8.0.fn.out_proj.weight', 'layers.layers.8.1.norm.weight', 'layers.layers.8.1.norm.bias', 'layers.layers.8.1.fn.0.proj.weight', 'layers.layers.8.1.fn.0.proj.bias', 'layers.layers.8.1.fn.2.weight', 'layers.layers.8.1.fn.2.bias', 'layers.layers.9.0.norm.weight', 'layers.layers.9.0.norm.bias', 'layers.layers.9.0.fn.qkv_proj.weight', 'layers.layers.9.0.fn.out_proj.weight', 'layers.layers.9.1.norm.weight', 'layers.layers.9.1.norm.bias', 'layers.layers.9.1.fn.0.proj.weight', 'layers.layers.9.1.fn.0.proj.bias', 'layers.layers.9.1.fn.2.weight', 'layers.layers.9.1.fn.2.bias', 'layers.layers.10.0.norm.weight', 'layers.layers.10.0.norm.bias', 'layers.layers.10.0.fn.qkv_proj.weight', 'layers.layers.10.0.fn.out_proj.weight', 'layers.layers.10.1.norm.weight', 'layers.layers.10.1.norm.bias', 'layers.layers.10.1.fn.0.proj.weight', 'layers.layers.10.1.fn.0.proj.bias', 'layers.layers.10.1.fn.2.weight', 'layers.layers.10.1.fn.2.bias', 'layers.layers.11.0.norm.weight', 'layers.layers.11.0.norm.bias', 'layers.layers.11.0.fn.qkv_proj.weight', 'layers.layers.11.0.fn.out_proj.weight', 'layers.layers.11.1.norm.weight', 'layers.layers.11.1.norm.bias', 'layers.layers.11.1.fn.0.proj.weight', 'layers.layers.11.1.fn.0.proj.bias', 'layers.layers.11.1.fn.2.weight', 'layers.layers.11.1.fn.2.bias', 'to_logits.weight', 'to_logits.bias', 'embedding.weight', 'post_norm.weight', 'post_norm.bias'])\n",
      "Loaded checkpoint from ./checkpoint_myopic_test/checkpoint_11_id_18.pt\n",
      "Epoch: 11, Validation loss: 1.9986681275897555\n"
     ]
    }
   ],
   "source": [
    "epoch, val_loss  = model_utils.load_checkpoint(args=argsclass(**{'checkpoint': './checkpoint_myopic_test/checkpoint_11_id_18.pt'}), model=model, force_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⁇  so i was speaking to bill gave it each one of the most people and applied to it and then they were still a city looking up the streaming camp this was the high deposit thought that the particular reg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.greedy_generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    input_txt='So I was speaking to Bill Ga',\n",
    "    max_len=100,\n",
    "    force_cpu=True,\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mgreedy_generate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA prominent limitation of \u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:217\u001b[0m, in \u001b[0;36mS4adapter.greedy_generate\u001b[0;34m(self, text, tokenizer, num_steps, device, temperature)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgreedy_generate\u001b[39m(\u001b[39mself\u001b[39m, text, tokenizer, num_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.greedy_generate('A prominent limitation of ', tokenizer=tokenizer, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import non_iid_dataloader as niiddl\n",
    "import lm_utils\n",
    "rl(niiddl)\n",
    "rl(lm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.70: 100%|██████████| 12/12 [00:19<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.0, PPL: 2.19421648979187, Avg Len: 67.19134521484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.72:  22%|██▏       | 2/9 [00:03<00:13,  1.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 28\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m duration \u001b[38;5;129;01min\u001b[39;00m durations:\n\u001b[1;32m     20\u001b[0m     dl \u001b[38;5;241m=\u001b[39m niiddl\u001b[38;5;241m.\u001b[39mget_data_loader(\n\u001b[1;32m     21\u001b[0m         corpus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     22\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         text_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     ppl, avg_len \u001b[38;5;241m=\u001b[39m lm_utils\u001b[38;5;241m.\u001b[39meval_corpus_perplexity(model, dl, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Avg Len: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:90\u001b[0m, in \u001b[0;36meval_corpus_perplexity\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     89\u001b[0m     tokens, token_lens \u001b[39m=\u001b[39m batch_to_device(batch, device)\n\u001b[0;32m---> 90\u001b[0m     cur_loss \u001b[39m=\u001b[39m eval_perplexity(model, tokens, token_lens, return_ppl\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     91\u001b[0m     losses\u001b[39m.\u001b[39mappend(cur_loss)\n\u001b[1;32m     92\u001b[0m     all_token_lens\u001b[39m.\u001b[39mappend(token_lens)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:76\u001b[0m, in \u001b[0;36meval_perplexity\u001b[0;34m(model, tokens, token_lens, return_ppl)\u001b[0m\n\u001b[1;32m     71\u001b[0m targets \u001b[39m=\u001b[39m mark_padding(targets, mask, pad_id\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     73\u001b[0m model_args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: tokens, \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m: mask} \u001b[39mif\u001b[39;00m isfalse(callable(\u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mget_args\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m))) \\\n\u001b[1;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39mget_args(tokens\u001b[39m=\u001b[39mtokens, mask\u001b[39m=\u001b[39mmask, lengths\u001b[39m=\u001b[39mtoken_lens)\n\u001b[0;32m---> 76\u001b[0m logits \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m     77\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(rearrange(logits, \u001b[39m'\u001b[39m\u001b[39mb n c -> b c n\u001b[39m\u001b[39m'\u001b[39m), targets, ignore_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m token_lens\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:290\u001b[0m, in \u001b[0;36mS4adapter.forward\u001b[0;34m(self, tokens, mask, lengths)\u001b[0m\n\u001b[1;32m    288\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(tokens)\n\u001b[1;32m    289\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mmasked_fill(\u001b[39m~\u001b[39mmask\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m exists(mask) \u001b[39melse\u001b[39;00m x\n\u001b[0;32m--> 290\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x, lengths, return_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:277\u001b[0m, in \u001b[0;36mS4adapter._forward\u001b[0;34m(self, u, lengths, return_states, states)\u001b[0m\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m-\u001b[39m latent\n\u001b[1;32m    276\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m states[i]\n\u001b[0;32m--> 277\u001b[0m x_out, state \u001b[39m=\u001b[39m s4(u\u001b[39m=\u001b[39;49mx, lengths\u001b[39m=\u001b[39;49mlengths, state\u001b[39m=\u001b[39;49mstate)\n\u001b[1;32m    278\u001b[0m x \u001b[39m=\u001b[39m x_out \u001b[39m+\u001b[39m x \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m    279\u001b[0m model_states_dict[i] \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mdetach() \u001b[39mif\u001b[39;00m return_states \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm/s4.py:1533\u001b[0m, in \u001b[0;36mS4.forward\u001b[0;34m(self, u, state, rate, lengths, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(y))\n\u001b[1;32m   1531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransposed: y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 1533\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_linear(y)\n\u001b[1;32m   1535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1536\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_gate(y \u001b[39m*\u001b[39m v)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "durations = [\n",
    "    0.0,\n",
    "    15.0,\n",
    "    30.0,\n",
    "    45.0,\n",
    "    60.0,\n",
    "    75.0,\n",
    "    90.0,\n",
    "    100.0,\n",
    "    120.0,\n",
    "    140.0,\n",
    "    180.0,\n",
    "    200.0,\n",
    "    250.0,\n",
    "    300.0,\n",
    "    400.0,\n",
    "    500.0,\n",
    "]\n",
    "for duration in durations:\n",
    "    dl = niiddl.get_data_loader(\n",
    "        corpus['test'], \n",
    "        tokenizer=tokenizer, \n",
    "        batch_size=100, \n",
    "        shuffle=False,\n",
    "        max_duration=duration,\n",
    "        text_only=True,\n",
    "    )\n",
    "    ppl, avg_len = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "    print(f\"Duration: {duration}, PPL: {ppl}, Avg Len: {avg_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = niiddl.get_data_loader(\n",
    "    corpus['train'], \n",
    "    tokenizer=tokenizer, \n",
    "    batch_size=20, \n",
    "    shuffle=True,\n",
    "    max_duration=100,\n",
    "    text_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    z = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perplexity: 417.11: 100%|██████████| 26/26 [01:22<00:00,  3.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479.1307067871094 1441.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ppl, avg_len = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "#print(ppl, avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perplexity: 459.58: 100%|██████████| 124/124 [00:18<00:00,  6.71it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167.10165405273438"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.eval_corpus_perplexity(model, dl, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 17, 54, 97, 3, 107, 3, 107, 3, 107]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'⁇  how are as as as'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.greedy_generate(model, tokenizer, 'how are', 10, force_cpu=True, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(lm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 30, 104, 6, 8]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.text_to_ids('hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens(['<sos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.additional_special_tokens_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_text(out[0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m token_lens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = torch.randn(2,3)\n",
    "token_lens = torch.tensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_eos(tkn, tkn_len, eos_id = 30):\n",
    "    tkn = tkn.clone() \n",
    "    tkn[torch.arange(tkn.shape[0], device=tkn_len.device, dtype=torch.int32), (tkn_len-1.0).to(torch.int32)] = eos_id\n",
    "    return tkn\n",
    "\n",
    "token_lens.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 78, 30, 104]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] + tokenizer.text_to_ids('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [178], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m add_eos(tokens, token_lens)\n",
      "Cell \u001b[0;32mIn [177], line 3\u001b[0m, in \u001b[0;36madd_eos\u001b[0;34m(tkn, tkn_len, eos_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_eos\u001b[39m(tkn, tkn_len, eos_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m      2\u001b[0m     tkn \u001b[38;5;241m=\u001b[39m tkn\u001b[38;5;241m.\u001b[39mclone() \n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtkn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtkn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtkn_len\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtkn_len\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m eos_id\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tkn\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "add_eos(tokens, token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = torch.tensor(\n",
    "    [[0,0,0],\n",
    "    [0,0,0]]\n",
    ", dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3837,  0.5211, -1.2230,  0.5048, -0.1723, -2.0018])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[~bt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm.s4 import S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =S4(d_model=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.randint(0, 100, (2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl(lm_utils)\n",
    "from lm_utils import S4adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.381408"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(\n",
    "    S4adapter(S4(d_model=712, measure='legs', mode='nplr', transposed=False, d_state=64), vocab_size=128)\n",
    ") / 1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = S4adapter(S4(d_model=2048, measure='legs', mode='nplr', transposed=False, d_state=512), vocab_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4adapter(\n",
       "  (model): S4(\n",
       "    (kernel): SSKernel(\n",
       "      (kernel): SSKernelNPLR()\n",
       "    )\n",
       "    (activation): GELU()\n",
       "    (dropout): Identity()\n",
       "    (output_linear): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      (1): GLU(dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(128, 2048)\n",
       "  (predict): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2048]) emb\n",
      "torch.Size([2, 3, 2048]) s4\n",
      "torch.Size([2, 3, 128]) logits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 128])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(torch.randint(0, 100, (2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelSigmoid(nn.Module):\n",
    "    \"\"\"\n",
    "    adapted : https://github.com/yandexdataschool/gumbel_lstm/blob/master/gumbel_sigmoid.py\n",
    "\n",
    "    A gumbel-sigmoid nonlinearity with gumbel(0,1) noize\n",
    "    In short, it's a function that mimics #[a>0] indicator where a is the logit\n",
    "    \n",
    "    Explaination and motivation: https://arxiv.org/abs/1611.01144\n",
    "    \n",
    "    Math:\n",
    "    Sigmoid is a softmax of two logits: a and 0\n",
    "    e^a / (e^a + e^0) = 1 / (1 + e^(0 - a)) = sigm(a)\n",
    "    \n",
    "    Gumbel-sigmoid is a gumbel-softmax for same logits:\n",
    "    gumbel_sigm(a) = e^([a+gumbel1]/t) / [ e^([a+gumbel1]/t) + e^(gumbel2/t)]\n",
    "    where t is temperature, gumbel1 and gumbel2 are two samples from gumbel noize: -log(-log(uniform(0,1)))\n",
    "    gumbel_sigm(a) = 1 / ( 1 +  e^(gumbel2/t - [a+gumbel1]/t) = 1 / ( 1+ e^(-[a + gumbel1 - gumbel2]/t)\n",
    "    gumbel_sigm(a) = sigm([a+gumbel1-gumbel2]/t)\n",
    "    \n",
    "    For computation reasons:\n",
    "    gumbel1-gumbel2 = -log(-log(uniform1(0,1)) +log(-log(uniform2(0,1)) = -log( log(uniform2(0,1)) / log(uniform1(0,1)) )\n",
    "    gumbel_sigm(a) = sigm([a-log(log(uniform2(0,1))/log(uniform1(0,1))]/t)\n",
    "    \n",
    "    \n",
    "    :param t: temperature of sampling. Lower means more spike-like sampling. Can be symbolic.\n",
    "    :param eps: a small number used for numerical stability\n",
    "    :returns: a callable that can (and should) be used as a nonlinearity\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            init_temperature=1.0,\n",
    "            final_temperature=0.1,\n",
    "            total_steps=10000, \n",
    "            eps=1e-20,\n",
    "            \n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.temperature=init_temperature\n",
    "        self.final_temperature=final_temperature\n",
    "        self.total_steps=total_steps\n",
    "        self.decay = (final_temperature/init_temperature)**(1/total_steps)\n",
    "        self.eps=eps\n",
    "\n",
    "    def step(self):\n",
    "        if self.temperature > self.final_temperature:\n",
    "            self.temperature *= self.decay\n",
    "         \n",
    "    def __call__(self,logits):\n",
    "        \"\"\"computes a gumbel sigmoid sample\"\"\"\n",
    "        temperature = self.temperature if self.training else self.final_temperature\n",
    "        \n",
    "        #sample from Gumbel(0, 1)\n",
    "        uniform1 = torch.rand_like(logits)\n",
    "        uniform2 = torch.rand_like(logits)\n",
    "        \n",
    "        noise = -torch.log(torch.log(uniform2 + self.eps)/torch.log(uniform1 + self.eps) +self.eps)\n",
    "        #draw a sample from the Gumbel-Sigmoid distribution\n",
    "        gumbel = ((logits + noise) / temperature).sigmoid()\n",
    "        if self.training:\n",
    "            self.step()\n",
    "        return gumbel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GumbelSigmoid()"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GumbelSigmoid(final_temperature=0.6)\n",
    "gb.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5119)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd = torch.distributions.exponential.Exponential(0.1).sample(torch.Size([100]))\n",
    "rnd = rnd / rnd.sum()\n",
    "\n",
    "(gb(rnd).norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(10, 73, 256)\n",
    "k = torch.randn(10, 73, 256)\n",
    "temp = 256**0.5\n",
    "pos_emb = torch.randn(73, 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused = torch.baddbmm(pos_emb, q, k.transpose(-1, -2), beta=1.0, alpha=temp)\n",
    "dots = torch.einsum('bnd,bmd->bnm', q, k) * temp + pos_emb\n",
    "torch.allclose(fused, dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 73, 73]) torch.Size([10, 8, 73, 73])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now with multi-heads, tricky bit is we need to make it batched i.e 3d, this means moving the head dim to the batch dim\n",
    "q = torch.randn(10, 8, 73, 32)\n",
    "k = torch.randn(10, 8, 73, 32)\n",
    "temp = 32**0.5\n",
    "pos_emb = torch.randn(8, 73, 73)\n",
    "\n",
    "#qb = rearrange(q, 'b h n d -> (b h) n d')\n",
    "#kb = rearrange(k, 'b h n d -> (b h) n d')\n",
    "qb,kb = map(partial(rearrange, 'b h n d -> (b h) n d'), (q,k))\n",
    "pos_emb_b = repeat(pos_emb, 'h n m -> (b h) n m', b=10)\n",
    "\n",
    "fused = torch.baddbmm(pos_emb_b, qb, kb.transpose(-1, -2), beta=1.0, alpha=temp)\n",
    "dots = torch.einsum('b h n d, b h m d -> b h n m', q, k) * temp + pos_emb\n",
    "\n",
    "print(fused.shape, dots.shape)\n",
    "fused = rearrange(fused, '(b h) n m -> b h n m', b=10, h=8)\n",
    "torch.allclose(fused, dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 73, 73])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6948, -1.2061,  0.6850,  ...,  1.0949,  0.7656,  0.3566],\n",
       "        [ 0.8898,  1.1649, -2.3278,  ...,  0.5976,  0.9025, -1.4097],\n",
       "        [-0.5865, -0.4260,  0.6259,  ..., -0.1008, -1.5885,  0.6942],\n",
       "        ...,\n",
       "        [ 0.2545,  0.1986,  0.7685,  ...,  1.5268,  0.5201,  1.5483],\n",
       "        [ 0.4820,  0.7004,  0.7175,  ...,  0.1674,  0.6084,  0.1248],\n",
       "        [-0.0952, -2.6570,  0.1465,  ..., -0.2255,  0.7898,  0.1224]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6948, -1.2061,  0.6850,  ...,  1.0949,  0.7656,  0.3566],\n",
       "        [ 0.8898,  1.1649, -2.3278,  ...,  0.5976,  0.9025, -1.4097],\n",
       "        [-0.5865, -0.4260,  0.6259,  ..., -0.1008, -1.5885,  0.6942],\n",
       "        ...,\n",
       "        [ 0.2545,  0.1986,  0.7685,  ...,  1.5268,  0.5201,  1.5483],\n",
       "        [ 0.4820,  0.7004,  0.7175,  ...,  0.1674,  0.6084,  0.1248],\n",
       "        [-0.0952, -2.6570,  0.1465,  ..., -0.2255,  0.7898,  0.1224]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
