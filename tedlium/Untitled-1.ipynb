{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f320a6f85e0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = [1.0]\n",
    "for i in range(10000):\n",
    "    state.append(state[-1] * (0.1/1)**(1/10000))\n",
    "plt.plot(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-10-31 00:32:10 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-10-31 00:32:12 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-10-31 00:32:12 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-10-31 00:32:12 nemo_logging:349] /exp/exp1/acp21rjf/lhotse/lhotse/lazy.py:388: UserWarning: A lambda was passed to LazyMapper: it may prevent you from forking this process. If you experience issues with num_workers > 0 in torch.utils.data.DataLoader, try passing a regular function instead.\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'tedlium'\n",
      "/exp/exp1/acp21rjf/deliberation/speachy/tedlium\n"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "corpus = tools.load_corpus()\n",
    "from importlib import reload as rl\n",
    "import non_iid_dataloader as niiddl, lhotse\n",
    "partition = niiddl.prepare_partition(corpus['train'])\n",
    "from tqdm import tqdm\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer, Transformer\n",
    "import torch\n",
    "import x_transformers, torch\n",
    "tk = tools.load_tokenizer()\n",
    "from omegaconf.omegaconf import OmegaConf\n",
    "%cd tedlium\n",
    "import lm_utils\n",
    "tokenizer = tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings = niiddl.prepare_partition(corpus['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lhotse\n",
    "import non_iid_dataloader as niiddl\n",
    "rl(niiddl),rl(lhotse)\n",
    "from lhotse.dataset.collation import collate_audio\n",
    "from lhotse.dataset.cut_transforms import plain_concat, individual_speaker_concat\n",
    "niiddl.plain_concat = plain_concat\n",
    "niiddl.individual_speaker_concat = individual_speaker_concat\n",
    "\n",
    "samples = niiddl.prepare_samples(meetings, max_allowed_utterance_gap=3.0, max_duration=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rl(tools)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils\n",
    "class argsclass:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl(lm_utils)\n",
    "model = lm_utils.load_model(lm_utils.load_config('./lm/decoder_test.yaml'), tools.load_tokenizer(), max_len=1862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lm(\n",
       "  (layers): transformer(\n",
       "    (positional_bias): DynamicPositionBias(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=64, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_logits): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (embedding): Embedding(128, 256)\n",
       "  (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'checkpoints_LM3': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints_LM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>,\n",
       " <module 'model_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/model_utils.py'>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(lm_utils), rl(model_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint_myopic_test/checkpoint_11_id_18.pt\n",
      "odict_keys(['layers.positional_bias.mlp.0.0.weight', 'layers.positional_bias.mlp.0.0.bias', 'layers.positional_bias.mlp.1.0.weight', 'layers.positional_bias.mlp.1.0.bias', 'layers.positional_bias.mlp.2.weight', 'layers.positional_bias.mlp.2.bias', 'layers.layers.0.0.norm.weight', 'layers.layers.0.0.norm.bias', 'layers.layers.0.0.fn.qkv_proj.weight', 'layers.layers.0.0.fn.out_proj.weight', 'layers.layers.0.1.norm.weight', 'layers.layers.0.1.norm.bias', 'layers.layers.0.1.fn.0.proj.weight', 'layers.layers.0.1.fn.0.proj.bias', 'layers.layers.0.1.fn.2.weight', 'layers.layers.0.1.fn.2.bias', 'layers.layers.1.0.norm.weight', 'layers.layers.1.0.norm.bias', 'layers.layers.1.0.fn.qkv_proj.weight', 'layers.layers.1.0.fn.out_proj.weight', 'layers.layers.1.1.norm.weight', 'layers.layers.1.1.norm.bias', 'layers.layers.1.1.fn.0.proj.weight', 'layers.layers.1.1.fn.0.proj.bias', 'layers.layers.1.1.fn.2.weight', 'layers.layers.1.1.fn.2.bias', 'layers.layers.2.0.norm.weight', 'layers.layers.2.0.norm.bias', 'layers.layers.2.0.fn.qkv_proj.weight', 'layers.layers.2.0.fn.out_proj.weight', 'layers.layers.2.1.norm.weight', 'layers.layers.2.1.norm.bias', 'layers.layers.2.1.fn.0.proj.weight', 'layers.layers.2.1.fn.0.proj.bias', 'layers.layers.2.1.fn.2.weight', 'layers.layers.2.1.fn.2.bias', 'layers.layers.3.0.norm.weight', 'layers.layers.3.0.norm.bias', 'layers.layers.3.0.fn.qkv_proj.weight', 'layers.layers.3.0.fn.out_proj.weight', 'layers.layers.3.1.norm.weight', 'layers.layers.3.1.norm.bias', 'layers.layers.3.1.fn.0.proj.weight', 'layers.layers.3.1.fn.0.proj.bias', 'layers.layers.3.1.fn.2.weight', 'layers.layers.3.1.fn.2.bias', 'layers.layers.4.0.norm.weight', 'layers.layers.4.0.norm.bias', 'layers.layers.4.0.fn.qkv_proj.weight', 'layers.layers.4.0.fn.out_proj.weight', 'layers.layers.4.1.norm.weight', 'layers.layers.4.1.norm.bias', 'layers.layers.4.1.fn.0.proj.weight', 'layers.layers.4.1.fn.0.proj.bias', 'layers.layers.4.1.fn.2.weight', 'layers.layers.4.1.fn.2.bias', 'layers.layers.5.0.norm.weight', 'layers.layers.5.0.norm.bias', 'layers.layers.5.0.fn.qkv_proj.weight', 'layers.layers.5.0.fn.out_proj.weight', 'layers.layers.5.1.norm.weight', 'layers.layers.5.1.norm.bias', 'layers.layers.5.1.fn.0.proj.weight', 'layers.layers.5.1.fn.0.proj.bias', 'layers.layers.5.1.fn.2.weight', 'layers.layers.5.1.fn.2.bias', 'layers.layers.6.0.norm.weight', 'layers.layers.6.0.norm.bias', 'layers.layers.6.0.fn.qkv_proj.weight', 'layers.layers.6.0.fn.out_proj.weight', 'layers.layers.6.1.norm.weight', 'layers.layers.6.1.norm.bias', 'layers.layers.6.1.fn.0.proj.weight', 'layers.layers.6.1.fn.0.proj.bias', 'layers.layers.6.1.fn.2.weight', 'layers.layers.6.1.fn.2.bias', 'layers.layers.7.0.norm.weight', 'layers.layers.7.0.norm.bias', 'layers.layers.7.0.fn.qkv_proj.weight', 'layers.layers.7.0.fn.out_proj.weight', 'layers.layers.7.1.norm.weight', 'layers.layers.7.1.norm.bias', 'layers.layers.7.1.fn.0.proj.weight', 'layers.layers.7.1.fn.0.proj.bias', 'layers.layers.7.1.fn.2.weight', 'layers.layers.7.1.fn.2.bias', 'layers.layers.8.0.norm.weight', 'layers.layers.8.0.norm.bias', 'layers.layers.8.0.fn.qkv_proj.weight', 'layers.layers.8.0.fn.out_proj.weight', 'layers.layers.8.1.norm.weight', 'layers.layers.8.1.norm.bias', 'layers.layers.8.1.fn.0.proj.weight', 'layers.layers.8.1.fn.0.proj.bias', 'layers.layers.8.1.fn.2.weight', 'layers.layers.8.1.fn.2.bias', 'layers.layers.9.0.norm.weight', 'layers.layers.9.0.norm.bias', 'layers.layers.9.0.fn.qkv_proj.weight', 'layers.layers.9.0.fn.out_proj.weight', 'layers.layers.9.1.norm.weight', 'layers.layers.9.1.norm.bias', 'layers.layers.9.1.fn.0.proj.weight', 'layers.layers.9.1.fn.0.proj.bias', 'layers.layers.9.1.fn.2.weight', 'layers.layers.9.1.fn.2.bias', 'layers.layers.10.0.norm.weight', 'layers.layers.10.0.norm.bias', 'layers.layers.10.0.fn.qkv_proj.weight', 'layers.layers.10.0.fn.out_proj.weight', 'layers.layers.10.1.norm.weight', 'layers.layers.10.1.norm.bias', 'layers.layers.10.1.fn.0.proj.weight', 'layers.layers.10.1.fn.0.proj.bias', 'layers.layers.10.1.fn.2.weight', 'layers.layers.10.1.fn.2.bias', 'layers.layers.11.0.norm.weight', 'layers.layers.11.0.norm.bias', 'layers.layers.11.0.fn.qkv_proj.weight', 'layers.layers.11.0.fn.out_proj.weight', 'layers.layers.11.1.norm.weight', 'layers.layers.11.1.norm.bias', 'layers.layers.11.1.fn.0.proj.weight', 'layers.layers.11.1.fn.0.proj.bias', 'layers.layers.11.1.fn.2.weight', 'layers.layers.11.1.fn.2.bias', 'to_logits.weight', 'to_logits.bias', 'embedding.weight', 'post_norm.weight', 'post_norm.bias'])\n",
      "Loaded checkpoint from ./checkpoint_myopic_test/checkpoint_11_id_18.pt\n",
      "Epoch: 11, Validation loss: 1.9986681275897555\n"
     ]
    }
   ],
   "source": [
    "epoch, val_loss  = model_utils.load_checkpoint(args=argsclass(**{'checkpoint': './checkpoint_myopic_test/checkpoint_11_id_18.pt'}), model=model, force_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⁇  so i was speaking to bill gave it each one of the most people and applied to it and then they were still a city looking up the streaming camp this was the high deposit thought that the particular reg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.greedy_generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    input_txt='So I was speaking to Bill Ga',\n",
    "    max_len=100,\n",
    "    force_cpu=True,\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mgreedy_generate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA prominent limitation of \u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:217\u001b[0m, in \u001b[0;36mS4adapter.greedy_generate\u001b[0;34m(self, text, tokenizer, num_steps, device, temperature)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgreedy_generate\u001b[39m(\u001b[39mself\u001b[39m, text, tokenizer, num_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.greedy_generate('A prominent limitation of ', tokenizer=tokenizer, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import non_iid_dataloader as niiddl\n",
    "import lm_utils\n",
    "rl(niiddl)\n",
    "rl(lm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.70: 100%|██████████| 12/12 [00:19<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.0, PPL: 2.19421648979187, Avg Len: 67.19134521484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.72:  22%|██▏       | 2/9 [00:03<00:13,  1.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 28\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m duration \u001b[38;5;129;01min\u001b[39;00m durations:\n\u001b[1;32m     20\u001b[0m     dl \u001b[38;5;241m=\u001b[39m niiddl\u001b[38;5;241m.\u001b[39mget_data_loader(\n\u001b[1;32m     21\u001b[0m         corpus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     22\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         text_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     ppl, avg_len \u001b[38;5;241m=\u001b[39m lm_utils\u001b[38;5;241m.\u001b[39meval_corpus_perplexity(model, dl, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Avg Len: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:90\u001b[0m, in \u001b[0;36meval_corpus_perplexity\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     89\u001b[0m     tokens, token_lens \u001b[39m=\u001b[39m batch_to_device(batch, device)\n\u001b[0;32m---> 90\u001b[0m     cur_loss \u001b[39m=\u001b[39m eval_perplexity(model, tokens, token_lens, return_ppl\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     91\u001b[0m     losses\u001b[39m.\u001b[39mappend(cur_loss)\n\u001b[1;32m     92\u001b[0m     all_token_lens\u001b[39m.\u001b[39mappend(token_lens)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:76\u001b[0m, in \u001b[0;36meval_perplexity\u001b[0;34m(model, tokens, token_lens, return_ppl)\u001b[0m\n\u001b[1;32m     71\u001b[0m targets \u001b[39m=\u001b[39m mark_padding(targets, mask, pad_id\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     73\u001b[0m model_args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: tokens, \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m: mask} \u001b[39mif\u001b[39;00m isfalse(callable(\u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mget_args\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m))) \\\n\u001b[1;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39mget_args(tokens\u001b[39m=\u001b[39mtokens, mask\u001b[39m=\u001b[39mmask, lengths\u001b[39m=\u001b[39mtoken_lens)\n\u001b[0;32m---> 76\u001b[0m logits \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m     77\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(rearrange(logits, \u001b[39m'\u001b[39m\u001b[39mb n c -> b c n\u001b[39m\u001b[39m'\u001b[39m), targets, ignore_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m token_lens\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:290\u001b[0m, in \u001b[0;36mS4adapter.forward\u001b[0;34m(self, tokens, mask, lengths)\u001b[0m\n\u001b[1;32m    288\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(tokens)\n\u001b[1;32m    289\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mmasked_fill(\u001b[39m~\u001b[39mmask\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m exists(mask) \u001b[39melse\u001b[39;00m x\n\u001b[0;32m--> 290\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x, lengths, return_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:277\u001b[0m, in \u001b[0;36mS4adapter._forward\u001b[0;34m(self, u, lengths, return_states, states)\u001b[0m\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m-\u001b[39m latent\n\u001b[1;32m    276\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m states[i]\n\u001b[0;32m--> 277\u001b[0m x_out, state \u001b[39m=\u001b[39m s4(u\u001b[39m=\u001b[39;49mx, lengths\u001b[39m=\u001b[39;49mlengths, state\u001b[39m=\u001b[39;49mstate)\n\u001b[1;32m    278\u001b[0m x \u001b[39m=\u001b[39m x_out \u001b[39m+\u001b[39m x \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m    279\u001b[0m model_states_dict[i] \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mdetach() \u001b[39mif\u001b[39;00m return_states \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm/s4.py:1533\u001b[0m, in \u001b[0;36mS4.forward\u001b[0;34m(self, u, state, rate, lengths, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(y))\n\u001b[1;32m   1531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransposed: y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 1533\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_linear(y)\n\u001b[1;32m   1535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1536\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_gate(y \u001b[39m*\u001b[39m v)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "durations = [\n",
    "    0.0,\n",
    "    15.0,\n",
    "    30.0,\n",
    "    45.0,\n",
    "    60.0,\n",
    "    75.0,\n",
    "    90.0,\n",
    "    100.0,\n",
    "    120.0,\n",
    "    140.0,\n",
    "    180.0,\n",
    "    200.0,\n",
    "    250.0,\n",
    "    300.0,\n",
    "    400.0,\n",
    "    500.0,\n",
    "]\n",
    "for duration in durations:\n",
    "    dl = niiddl.get_data_loader(\n",
    "        corpus['test'], \n",
    "        tokenizer=tokenizer, \n",
    "        batch_size=100, \n",
    "        shuffle=False,\n",
    "        max_duration=duration,\n",
    "        text_only=True,\n",
    "    )\n",
    "    ppl, avg_len = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "    print(f\"Duration: {duration}, PPL: {ppl}, Avg Len: {avg_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = niiddl.get_data_loader(\n",
    "    corpus['train'], \n",
    "    tokenizer=tokenizer, \n",
    "    batch_size=20, \n",
    "    shuffle=True,\n",
    "    max_duration=100,\n",
    "    text_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    z = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perplexity: 417.11: 100%|██████████| 26/26 [01:22<00:00,  3.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479.1307067871094 1441.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ppl, avg_len = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "#print(ppl, avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perplexity: 459.58: 100%|██████████| 124/124 [00:18<00:00,  6.71it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167.10165405273438"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.eval_corpus_perplexity(model, dl, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 17, 54, 97, 3, 107, 3, 107, 3, 107]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'⁇  how are as as as'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.greedy_generate(model, tokenizer, 'how are', 10, force_cpu=True, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(lm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 30, 104, 6, 8]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.text_to_ids('hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens(['<sos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.additional_special_tokens_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_text(out[0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m token_lens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = torch.randn(2,3)\n",
    "token_lens = torch.tensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_eos(tkn, tkn_len, eos_id = 30):\n",
    "    tkn = tkn.clone() \n",
    "    tkn[torch.arange(tkn.shape[0], device=tkn_len.device, dtype=torch.int32), (tkn_len-1.0).to(torch.int32)] = eos_id\n",
    "    return tkn\n",
    "\n",
    "token_lens.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 78, 30, 104]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] + tokenizer.text_to_ids('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [178], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m add_eos(tokens, token_lens)\n",
      "Cell \u001b[0;32mIn [177], line 3\u001b[0m, in \u001b[0;36madd_eos\u001b[0;34m(tkn, tkn_len, eos_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_eos\u001b[39m(tkn, tkn_len, eos_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m      2\u001b[0m     tkn \u001b[38;5;241m=\u001b[39m tkn\u001b[38;5;241m.\u001b[39mclone() \n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtkn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtkn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtkn_len\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtkn_len\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m eos_id\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tkn\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "add_eos(tokens, token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = torch.tensor(\n",
    "    [[0,0,0],\n",
    "    [0,0,0]]\n",
    ", dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3837,  0.5211, -1.2230,  0.5048, -0.1723, -2.0018])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[~bt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm.s4 import S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =S4(d_model=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.randint(0, 100, (2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl(lm_utils)\n",
    "from lm_utils import S4adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.381408"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(\n",
    "    S4adapter(S4(d_model=712, measure='legs', mode='nplr', transposed=False, d_state=64), vocab_size=128)\n",
    ") / 1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = S4adapter(S4(d_model=2048, measure='legs', mode='nplr', transposed=False, d_state=512), vocab_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4adapter(\n",
       "  (model): S4(\n",
       "    (kernel): SSKernel(\n",
       "      (kernel): SSKernelNPLR()\n",
       "    )\n",
       "    (activation): GELU()\n",
       "    (dropout): Identity()\n",
       "    (output_linear): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      (1): GLU(dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(128, 2048)\n",
       "  (predict): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2048]) emb\n",
      "torch.Size([2, 3, 2048]) s4\n",
      "torch.Size([2, 3, 128]) logits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 128])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(torch.randint(0, 100, (2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 100, (2,3)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
