{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-10-31 00:32:10 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-10-31 00:32:12 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-10-31 00:32:12 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-10-31 00:32:12 nemo_logging:349] /exp/exp1/acp21rjf/lhotse/lhotse/lazy.py:388: UserWarning: A lambda was passed to LazyMapper: it may prevent you from forking this process. If you experience issues with num_workers > 0 in torch.utils.data.DataLoader, try passing a regular function instead.\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'tedlium'\n",
      "/exp/exp1/acp21rjf/deliberation/speachy/tedlium\n"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "corpus = tools.load_corpus()\n",
    "from importlib import reload as rl\n",
    "import non_iid_dataloader as niiddl, lhotse\n",
    "partition = niiddl.prepare_partition(corpus['train'])\n",
    "from tqdm import tqdm\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer, Transformer\n",
    "import torch\n",
    "import x_transformers, torch\n",
    "tk = tools.load_tokenizer()\n",
    "from omegaconf.omegaconf import OmegaConf\n",
    "%cd tedlium\n",
    "import lm_utils\n",
    "tokenizer = tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetings = niiddl.prepare_partition(corpus['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lhotse\n",
    "import non_iid_dataloader as niiddl\n",
    "rl(niiddl),rl(lhotse)\n",
    "from lhotse.dataset.collation import collate_audio\n",
    "from lhotse.dataset.cut_transforms import plain_concat, individual_speaker_concat\n",
    "niiddl.plain_concat = plain_concat\n",
    "niiddl.individual_speaker_concat = individual_speaker_concat\n",
    "\n",
    "samples = niiddl.prepare_samples(meetings, max_allowed_utterance_gap=3.0, max_duration=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rl(tools)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils\n",
    "class argsclass:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl(lm_utils)\n",
    "model = lm_utils.load_model(lm_utils.load_config('./lm/decoder_test.yaml'), tools.load_tokenizer(), max_len=1862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lm(\n",
       "  (layers): transformer(\n",
       "    (positional_bias): DynamicPositionBias(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=64, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): MyopicAttention(\n",
       "            (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Sequential(\n",
       "            (0): GLU(\n",
       "              (act): SiLU()\n",
       "              (proj): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_logits): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (embedding): Embedding(128, 256)\n",
       "  (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'checkpoints_LM3': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints_LM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>,\n",
       " <module 'model_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/model_utils.py'>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(lm_utils), rl(model_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint_myopic_test/checkpoint_11_id_18.pt\n",
      "odict_keys(['layers.positional_bias.mlp.0.0.weight', 'layers.positional_bias.mlp.0.0.bias', 'layers.positional_bias.mlp.1.0.weight', 'layers.positional_bias.mlp.1.0.bias', 'layers.positional_bias.mlp.2.weight', 'layers.positional_bias.mlp.2.bias', 'layers.layers.0.0.norm.weight', 'layers.layers.0.0.norm.bias', 'layers.layers.0.0.fn.qkv_proj.weight', 'layers.layers.0.0.fn.out_proj.weight', 'layers.layers.0.1.norm.weight', 'layers.layers.0.1.norm.bias', 'layers.layers.0.1.fn.0.proj.weight', 'layers.layers.0.1.fn.0.proj.bias', 'layers.layers.0.1.fn.2.weight', 'layers.layers.0.1.fn.2.bias', 'layers.layers.1.0.norm.weight', 'layers.layers.1.0.norm.bias', 'layers.layers.1.0.fn.qkv_proj.weight', 'layers.layers.1.0.fn.out_proj.weight', 'layers.layers.1.1.norm.weight', 'layers.layers.1.1.norm.bias', 'layers.layers.1.1.fn.0.proj.weight', 'layers.layers.1.1.fn.0.proj.bias', 'layers.layers.1.1.fn.2.weight', 'layers.layers.1.1.fn.2.bias', 'layers.layers.2.0.norm.weight', 'layers.layers.2.0.norm.bias', 'layers.layers.2.0.fn.qkv_proj.weight', 'layers.layers.2.0.fn.out_proj.weight', 'layers.layers.2.1.norm.weight', 'layers.layers.2.1.norm.bias', 'layers.layers.2.1.fn.0.proj.weight', 'layers.layers.2.1.fn.0.proj.bias', 'layers.layers.2.1.fn.2.weight', 'layers.layers.2.1.fn.2.bias', 'layers.layers.3.0.norm.weight', 'layers.layers.3.0.norm.bias', 'layers.layers.3.0.fn.qkv_proj.weight', 'layers.layers.3.0.fn.out_proj.weight', 'layers.layers.3.1.norm.weight', 'layers.layers.3.1.norm.bias', 'layers.layers.3.1.fn.0.proj.weight', 'layers.layers.3.1.fn.0.proj.bias', 'layers.layers.3.1.fn.2.weight', 'layers.layers.3.1.fn.2.bias', 'layers.layers.4.0.norm.weight', 'layers.layers.4.0.norm.bias', 'layers.layers.4.0.fn.qkv_proj.weight', 'layers.layers.4.0.fn.out_proj.weight', 'layers.layers.4.1.norm.weight', 'layers.layers.4.1.norm.bias', 'layers.layers.4.1.fn.0.proj.weight', 'layers.layers.4.1.fn.0.proj.bias', 'layers.layers.4.1.fn.2.weight', 'layers.layers.4.1.fn.2.bias', 'layers.layers.5.0.norm.weight', 'layers.layers.5.0.norm.bias', 'layers.layers.5.0.fn.qkv_proj.weight', 'layers.layers.5.0.fn.out_proj.weight', 'layers.layers.5.1.norm.weight', 'layers.layers.5.1.norm.bias', 'layers.layers.5.1.fn.0.proj.weight', 'layers.layers.5.1.fn.0.proj.bias', 'layers.layers.5.1.fn.2.weight', 'layers.layers.5.1.fn.2.bias', 'layers.layers.6.0.norm.weight', 'layers.layers.6.0.norm.bias', 'layers.layers.6.0.fn.qkv_proj.weight', 'layers.layers.6.0.fn.out_proj.weight', 'layers.layers.6.1.norm.weight', 'layers.layers.6.1.norm.bias', 'layers.layers.6.1.fn.0.proj.weight', 'layers.layers.6.1.fn.0.proj.bias', 'layers.layers.6.1.fn.2.weight', 'layers.layers.6.1.fn.2.bias', 'layers.layers.7.0.norm.weight', 'layers.layers.7.0.norm.bias', 'layers.layers.7.0.fn.qkv_proj.weight', 'layers.layers.7.0.fn.out_proj.weight', 'layers.layers.7.1.norm.weight', 'layers.layers.7.1.norm.bias', 'layers.layers.7.1.fn.0.proj.weight', 'layers.layers.7.1.fn.0.proj.bias', 'layers.layers.7.1.fn.2.weight', 'layers.layers.7.1.fn.2.bias', 'layers.layers.8.0.norm.weight', 'layers.layers.8.0.norm.bias', 'layers.layers.8.0.fn.qkv_proj.weight', 'layers.layers.8.0.fn.out_proj.weight', 'layers.layers.8.1.norm.weight', 'layers.layers.8.1.norm.bias', 'layers.layers.8.1.fn.0.proj.weight', 'layers.layers.8.1.fn.0.proj.bias', 'layers.layers.8.1.fn.2.weight', 'layers.layers.8.1.fn.2.bias', 'layers.layers.9.0.norm.weight', 'layers.layers.9.0.norm.bias', 'layers.layers.9.0.fn.qkv_proj.weight', 'layers.layers.9.0.fn.out_proj.weight', 'layers.layers.9.1.norm.weight', 'layers.layers.9.1.norm.bias', 'layers.layers.9.1.fn.0.proj.weight', 'layers.layers.9.1.fn.0.proj.bias', 'layers.layers.9.1.fn.2.weight', 'layers.layers.9.1.fn.2.bias', 'layers.layers.10.0.norm.weight', 'layers.layers.10.0.norm.bias', 'layers.layers.10.0.fn.qkv_proj.weight', 'layers.layers.10.0.fn.out_proj.weight', 'layers.layers.10.1.norm.weight', 'layers.layers.10.1.norm.bias', 'layers.layers.10.1.fn.0.proj.weight', 'layers.layers.10.1.fn.0.proj.bias', 'layers.layers.10.1.fn.2.weight', 'layers.layers.10.1.fn.2.bias', 'layers.layers.11.0.norm.weight', 'layers.layers.11.0.norm.bias', 'layers.layers.11.0.fn.qkv_proj.weight', 'layers.layers.11.0.fn.out_proj.weight', 'layers.layers.11.1.norm.weight', 'layers.layers.11.1.norm.bias', 'layers.layers.11.1.fn.0.proj.weight', 'layers.layers.11.1.fn.0.proj.bias', 'layers.layers.11.1.fn.2.weight', 'layers.layers.11.1.fn.2.bias', 'to_logits.weight', 'to_logits.bias', 'embedding.weight', 'post_norm.weight', 'post_norm.bias'])\n",
      "Loaded checkpoint from ./checkpoint_myopic_test/checkpoint_11_id_18.pt\n",
      "Epoch: 11, Validation loss: 1.9986681275897555\n"
     ]
    }
   ],
   "source": [
    "epoch, val_loss  = model_utils.load_checkpoint(args=argsclass(**{'checkpoint': './checkpoint_myopic_test/checkpoint_11_id_18.pt'}), model=model, force_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⁇  so i was speaking to bill gave it each one of the most people and applied to it and then they were still a city looking up the streaming camp this was the high deposit thought that the particular reg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.greedy_generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    input_txt='So I was speaking to Bill Ga',\n",
    "    max_len=100,\n",
    "    force_cpu=True,\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mgreedy_generate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA prominent limitation of \u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:217\u001b[0m, in \u001b[0;36mS4adapter.greedy_generate\u001b[0;34m(self, text, tokenizer, num_steps, device, temperature)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgreedy_generate\u001b[39m(\u001b[39mself\u001b[39m, text, tokenizer, num_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.greedy_generate('A prominent limitation of ', tokenizer=tokenizer, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import non_iid_dataloader as niiddl\n",
    "import lm_utils\n",
    "rl(niiddl)\n",
    "rl(lm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.70: 100%|██████████| 12/12 [00:19<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.0, PPL: 2.19421648979187, Avg Len: 67.19134521484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.72:  22%|██▏       | 2/9 [00:03<00:13,  1.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 28\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m duration \u001b[38;5;129;01min\u001b[39;00m durations:\n\u001b[1;32m     20\u001b[0m     dl \u001b[38;5;241m=\u001b[39m niiddl\u001b[38;5;241m.\u001b[39mget_data_loader(\n\u001b[1;32m     21\u001b[0m         corpus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     22\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         text_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     ppl, avg_len \u001b[38;5;241m=\u001b[39m lm_utils\u001b[38;5;241m.\u001b[39meval_corpus_perplexity(model, dl, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Avg Len: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:90\u001b[0m, in \u001b[0;36meval_corpus_perplexity\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     89\u001b[0m     tokens, token_lens \u001b[39m=\u001b[39m batch_to_device(batch, device)\n\u001b[0;32m---> 90\u001b[0m     cur_loss \u001b[39m=\u001b[39m eval_perplexity(model, tokens, token_lens, return_ppl\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     91\u001b[0m     losses\u001b[39m.\u001b[39mappend(cur_loss)\n\u001b[1;32m     92\u001b[0m     all_token_lens\u001b[39m.\u001b[39mappend(token_lens)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:76\u001b[0m, in \u001b[0;36meval_perplexity\u001b[0;34m(model, tokens, token_lens, return_ppl)\u001b[0m\n\u001b[1;32m     71\u001b[0m targets \u001b[39m=\u001b[39m mark_padding(targets, mask, pad_id\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     73\u001b[0m model_args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: tokens, \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m: mask} \u001b[39mif\u001b[39;00m isfalse(callable(\u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mget_args\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m))) \\\n\u001b[1;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39mget_args(tokens\u001b[39m=\u001b[39mtokens, mask\u001b[39m=\u001b[39mmask, lengths\u001b[39m=\u001b[39mtoken_lens)\n\u001b[0;32m---> 76\u001b[0m logits \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_args)\n\u001b[1;32m     77\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(rearrange(logits, \u001b[39m'\u001b[39m\u001b[39mb n c -> b c n\u001b[39m\u001b[39m'\u001b[39m), targets, ignore_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m token_lens\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:290\u001b[0m, in \u001b[0;36mS4adapter.forward\u001b[0;34m(self, tokens, mask, lengths)\u001b[0m\n\u001b[1;32m    288\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(tokens)\n\u001b[1;32m    289\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mmasked_fill(\u001b[39m~\u001b[39mmask\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m exists(mask) \u001b[39melse\u001b[39;00m x\n\u001b[0;32m--> 290\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(x, lengths, return_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py:277\u001b[0m, in \u001b[0;36mS4adapter._forward\u001b[0;34m(self, u, lengths, return_states, states)\u001b[0m\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m-\u001b[39m latent\n\u001b[1;32m    276\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m states[i]\n\u001b[0;32m--> 277\u001b[0m x_out, state \u001b[39m=\u001b[39m s4(u\u001b[39m=\u001b[39;49mx, lengths\u001b[39m=\u001b[39;49mlengths, state\u001b[39m=\u001b[39;49mstate)\n\u001b[1;32m    278\u001b[0m x \u001b[39m=\u001b[39m x_out \u001b[39m+\u001b[39m x \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m    279\u001b[0m model_states_dict[i] \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mdetach() \u001b[39mif\u001b[39;00m return_states \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm/s4.py:1533\u001b[0m, in \u001b[0;36mS4.forward\u001b[0;34m(self, u, state, rate, lengths, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(y))\n\u001b[1;32m   1531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransposed: y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 1533\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_linear(y)\n\u001b[1;32m   1535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1536\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_gate(y \u001b[39m*\u001b[39m v)\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/store/store1/software/bin/anaconda3/envs/k2_custom-nemo/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "durations = [\n",
    "    0.0,\n",
    "    15.0,\n",
    "    30.0,\n",
    "    45.0,\n",
    "    60.0,\n",
    "    75.0,\n",
    "    90.0,\n",
    "    100.0,\n",
    "    120.0,\n",
    "    140.0,\n",
    "    180.0,\n",
    "    200.0,\n",
    "    250.0,\n",
    "    300.0,\n",
    "    400.0,\n",
    "    500.0,\n",
    "]\n",
    "for duration in durations:\n",
    "    dl = niiddl.get_data_loader(\n",
    "        corpus['test'], \n",
    "        tokenizer=tokenizer, \n",
    "        batch_size=100, \n",
    "        shuffle=False,\n",
    "        max_duration=duration,\n",
    "        text_only=True,\n",
    "    )\n",
    "    ppl, avg_len = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "    print(f\"Duration: {duration}, PPL: {ppl}, Avg Len: {avg_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = niiddl.get_data_loader(\n",
    "    corpus['train'], \n",
    "    tokenizer=tokenizer, \n",
    "    batch_size=20, \n",
    "    shuffle=True,\n",
    "    max_duration=100,\n",
    "    text_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    z = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perplexity: 417.11: 100%|██████████| 26/26 [01:22<00:00,  3.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479.1307067871094 1441.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ppl, avg_len = lm_utils.eval_corpus_perplexity(model, dl, device='cpu')\n",
    "#print(ppl, avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perplexity: 459.58: 100%|██████████| 124/124 [00:18<00:00,  6.71it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167.10165405273438"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.eval_corpus_perplexity(model, dl, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 17, 54, 97, 3, 107, 3, 107, 3, 107]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'⁇  how are as as as'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_utils.greedy_generate(model, tokenizer, 'how are', 10, force_cpu=True, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lm_utils' from '/exp/exp1/acp21rjf/deliberation/speachy/tedlium/lm_utils.py'>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(lm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 30, 104, 6, 8]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.text_to_ids('hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens(['<sos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.additional_special_tokens_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_text(out[0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m token_lens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = torch.randn(2,3)\n",
    "token_lens = torch.tensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_eos(tkn, tkn_len, eos_id = 30):\n",
    "    tkn = tkn.clone() \n",
    "    tkn[torch.arange(tkn.shape[0], device=tkn_len.device, dtype=torch.int32), (tkn_len-1.0).to(torch.int32)] = eos_id\n",
    "    return tkn\n",
    "\n",
    "token_lens.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 78, 30, 104]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] + tokenizer.text_to_ids('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [178], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m add_eos(tokens, token_lens)\n",
      "Cell \u001b[0;32mIn [177], line 3\u001b[0m, in \u001b[0;36madd_eos\u001b[0;34m(tkn, tkn_len, eos_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_eos\u001b[39m(tkn, tkn_len, eos_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m      2\u001b[0m     tkn \u001b[38;5;241m=\u001b[39m tkn\u001b[38;5;241m.\u001b[39mclone() \n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtkn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtkn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtkn_len\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtkn_len\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m eos_id\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tkn\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "add_eos(tokens, token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = torch.tensor(\n",
    "    [[0,0,0],\n",
    "    [0,0,0]]\n",
    ", dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3837,  0.5211, -1.2230,  0.5048, -0.1723, -2.0018])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[~bt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm.s4 import S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =S4(d_model=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.randint(0, 100, (2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl(lm_utils)\n",
    "from lm_utils import S4adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.381408"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(\n",
    "    S4adapter(S4(d_model=712, measure='legs', mode='nplr', transposed=False, d_state=64), vocab_size=128)\n",
    ") / 1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = S4adapter(S4(d_model=2048, measure='legs', mode='nplr', transposed=False, d_state=512), vocab_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4adapter(\n",
       "  (model): S4(\n",
       "    (kernel): SSKernel(\n",
       "      (kernel): SSKernelNPLR()\n",
       "    )\n",
       "    (activation): GELU()\n",
       "    (dropout): Identity()\n",
       "    (output_linear): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      (1): GLU(dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(128, 2048)\n",
       "  (predict): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2048]) emb\n",
      "torch.Size([2, 3, 2048]) s4\n",
      "torch.Size([2, 3, 128]) logits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 128])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(torch.randint(0, 100, (2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 100, (2,3)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('k2_custom-nemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94c8ffa67fdebd9384b5746b8c4850bc2cec88ff489992126dcd0aca228c275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
