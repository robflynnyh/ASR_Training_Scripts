
dataset: 'PG19'

model:
  tokenizer:
    dir: "./tokenizer/tokenizer_spe_bpe_v16001/" # path to directory which contains either tokenizer.model (bpe) or vocab.txt (wpe)
    type: bpe  # has to be bpe (u have no choice)
  
  modeltype: feedback_tlm_pg19

  feedback_tlm_pg19:
    d_model: 1024
    n_layers: 5
    n_heads: 8
    dim_head: 128
    dropout: 0.0
    temperature: 15.5
    intermediate_loss: false
    kwargs:
      ff_mult: 1
      tie_embedding: false
      checkpoint_every_n: 1
      shared_kv: true
