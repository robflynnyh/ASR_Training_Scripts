
dataset: 'TED'

model:
  tokenizer:
    dir: "./tedlium/tokenizers/tokenizer_spe_bpe_v128/" # path to directory which contains either tokenizer.model (bpe) or vocab.txt (wpe)
    type: bpe  # has to be bpe (u have no choice)
  
  modeltype: qknorm_shared

  qknorm_shared:
    d_model: 256
    n_layers: 12
    n_heads: 8
    dim_head: 32
    dropout: 0.0
    temperature: 15.5
    intermediate_loss: false
    kwargs:
      ff_mult: 4
      tie_embedding: false
      checkpoint_every_n: 1
      shared_kv: true
      talking_heads: false
    add_ons:
      sep_token:
        dim: 256
      next_sentence_pred:
        dim: 'vocab'