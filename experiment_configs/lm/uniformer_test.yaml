
dataset: 'TED'

model:
  tokenizer:
    dir: "./lm/tokenizers/tokenizer_spe_bpe_v29/" # path to directory which contains either tokenizer.model (bpe) or vocab.txt (wpe)
    type: bpe  # has to be bpe (u have no choice)
  
  modeltype: unitformer

  unitformer:
    d_model: 256
    depth: 5
    n_heads: 4
    dim_head: 64
    dropout: 0.0
    kwargs:
      inner_depth: 5
      ff_mult: 3
      tie_embedding: false
      checkpoint_every_n: 1
      shared_kv: true
      talking_heads: false
