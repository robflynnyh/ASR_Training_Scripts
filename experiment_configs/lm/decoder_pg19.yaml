
dataset: 'TED'

model:
  tokenizer:
    dir: "./lm/tokenizers/tokenizer_spe_bpe_v1500/" # path to directory which contains either tokenizer.model (bpe) or vocab.txt (wpe)
    type: bpe  # has to be bpe (u have no choice)
  
  modeltype: qknorm_shared


  qknorm_shared:
    d_model: 256
    n_layers: 12
    n_heads: 8
    dim_head: 32
    dropout: 0.1
    temperature: 15.5
    kwargs:
      ff_mult: 4
      tie_embedding: false
      checkpoint_every_n: 1
      shared_kv: true
      talking_heads: false
